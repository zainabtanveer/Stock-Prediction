{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNf0vgbYgjoYDI+bUsBs3OS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zainabtanveer/Stock-Prediction/blob/master/Copy_of_Copy_of_Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaE1NaxIuGu5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "1b364585-978f-4f02-a248-9ce3ba438ed7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbJMz801wSmY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "1da55688-c181-4208-a30e-e2fbf4015f79"
      },
      "source": [
        "!pip install yahoo-fin\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting yahoo-fin\n",
            "  Downloading https://files.pythonhosted.org/packages/d3/5c/6bf0c0147cc94d643e2a2413d0a9b27967e964ee99f88f26db93a0b963b8/yahoo_fin-0.8.6-py3-none-any.whl\n",
            "Installing collected packages: yahoo-fin\n",
            "Successfully installed yahoo-fin-0.8.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzqYpdddxBco",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2e5bd446-b041-40e1-dfbf-b87779411e55"
      },
      "source": [
        "!pip install requests_html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting requests_html\n",
            "  Downloading https://files.pythonhosted.org/packages/24/bc/a4380f09bab3a776182578ce6b2771e57259d0d4dbce178205779abdc347/requests_html-0.10.0-py3-none-any.whl\n",
            "Collecting w3lib\n",
            "  Downloading https://files.pythonhosted.org/packages/a3/59/b6b14521090e7f42669cafdb84b0ab89301a42f1f1a82fcf5856661ea3a7/w3lib-1.22.0-py2.py3-none-any.whl\n",
            "Collecting pyppeteer>=0.0.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/4b/3c2aabdd1b91fa52aa9de6cde33b488b0592b4d48efb0ad9efbf71c49f5b/pyppeteer-0.2.2-py3-none-any.whl (145kB)\n",
            "\r\u001b[K     |██▎                             | 10kB 16.5MB/s eta 0:00:01\r\u001b[K     |████▌                           | 20kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 30kB 10.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 40kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 51kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 61kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 81kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 92kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 102kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 112kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 122kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 133kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 143kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 153kB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: bs4 in /usr/local/lib/python3.6/dist-packages (from requests_html) (0.0.1)\n",
            "Collecting parse\n",
            "  Downloading https://files.pythonhosted.org/packages/22/35/930b6d670cac8ead61dfc05f0e62994ab0697573de17a3231d65631f16d5/parse-1.16.0.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from requests_html) (2.23.0)\n",
            "Collecting pyquery\n",
            "  Downloading https://files.pythonhosted.org/packages/78/43/95d42e386c61cb639d1a0b94f0c0b9f0b7d6b981ad3c043a836c8b5bc68b/pyquery-1.4.1-py2.py3-none-any.whl\n",
            "Collecting fake-useragent\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/79/af647635d6968e2deb57a208d309f6069d31cb138066d7e821e575112a80/fake-useragent-0.1.11.tar.gz\n",
            "Requirement already satisfied: six>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from w3lib->requests_html) (1.15.0)\n",
            "Collecting websockets<9.0,>=8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/d9/856af84843912e2853b1b6e898ac8b802989fcf9ecf8e8445a1da263bf3b/websockets-8.1-cp36-cp36m-manylinux2010_x86_64.whl (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.3MB/s \n",
            "\u001b[?25hCollecting appdirs<2.0.0,>=1.4.3\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl\n",
            "Collecting pyee<8.0.0,>=7.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/f6/28/1cedd44c27907f1507a28ff2d36fc6cdb981c9deff2fa288bc48a700c7c9/pyee-7.0.2-py2.py3-none-any.whl\n",
            "Collecting tqdm<5.0.0,>=4.42.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/88/7b0ea5fa8192d1733dea459a9e3059afc87819cb4072c43263f2ec7ab768/tqdm-4.48.0-py2.py3-none-any.whl (67kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.5MB/s \n",
            "\u001b[?25hCollecting urllib3<2.0.0,>=1.25.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/f0/a391d1463ebb1b233795cabfc0ef38d3db4442339de68f847026199e69d7/urllib3-1.25.10-py2.py3-none-any.whl (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 15.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from bs4->requests_html) (4.6.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->requests_html) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->requests_html) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->requests_html) (3.0.4)\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.6/dist-packages (from pyquery->requests_html) (4.2.6)\n",
            "Collecting cssselect>0.7.9\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: parse, fake-useragent\n",
            "  Building wheel for parse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parse: filename=parse-1.16.0-cp36-none-any.whl size=23996 sha256=23a139a00789532a8ae6c4430fabe660954c95517df72f5391ee4f4d90cdad03\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/ca/7d/4e6d687c81f1110b47140845d6dce4e6d7cdae0996caeca560\n",
            "  Building wheel for fake-useragent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fake-useragent: filename=fake_useragent-0.1.11-cp36-none-any.whl size=13484 sha256=88c5a4b2b0ba2a1f500e4cb424bac5621dffa90810463cdb856a514c4baac43b\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/63/09/d1dc15179f175357d3f5c00cbffbac37f9e8690d80545143ff\n",
            "Successfully built parse fake-useragent\n",
            "\u001b[31mERROR: kaggle 1.5.6 has requirement urllib3<1.25,>=1.21.1, but you'll have urllib3 1.25.10 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: w3lib, websockets, appdirs, pyee, tqdm, urllib3, pyppeteer, parse, cssselect, pyquery, fake-useragent, requests-html\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed appdirs-1.4.4 cssselect-1.1.0 fake-useragent-0.1.11 parse-1.16.0 pyee-7.0.2 pyppeteer-0.2.2 pyquery-1.4.1 requests-html-0.10.0 tqdm-4.48.0 urllib3-1.25.10 w3lib-1.22.0 websockets-8.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tqdm",
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yU4EnpfnxqxS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from yahoo_fin import stock_info as si\n",
        "from collections import deque\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slz68-kLxx37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set seed, so we can get the same results after rerunning several times\n",
        "np.random.seed(314)\n",
        "tf.random.set_seed(314)\n",
        "random.seed(314)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCnj09Xjx56y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, \n",
        "                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
        "    # see if ticker is already a loaded stock from yahoo finance\n",
        "    if isinstance(ticker, str):\n",
        "        # load it from yahoo_fin library\n",
        "        df = si.get_data(ticker)\n",
        "    elif isinstance(ticker, pd.DataFrame):\n",
        "        # already loaded, use it directly\n",
        "        df = ticker\n",
        "    # this will contain all the elements we want to return from this function\n",
        "    result = {}\n",
        "    # we will also return the original dataframe itself\n",
        "    result['df'] = df.copy()\n",
        "    # make sure that the passed feature_columns exist in the dataframe\n",
        "    for col in feature_columns:\n",
        "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
        "    if scale:\n",
        "        column_scaler = {}\n",
        "        # scale the data (prices) from 0 to 1\n",
        "        for column in feature_columns:\n",
        "            scaler = preprocessing.MinMaxScaler()\n",
        "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
        "            column_scaler[column] = scaler\n",
        "\n",
        "        # add the MinMaxScaler instances to the result returned\n",
        "        result[\"column_scaler\"] = column_scaler\n",
        "    # add the target column (label) by shifting by `lookup_step`\n",
        "    df['future'] = df['adjclose'].shift(-lookup_step)\n",
        "    # last `lookup_step` columns contains NaN in future column\n",
        "    # get them before droping NaNs\n",
        "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
        "    # drop NaNs\n",
        "    df.dropna(inplace=True)\n",
        "    sequence_data = []\n",
        "    sequences = deque(maxlen=n_steps)\n",
        "    for entry, target in zip(df[feature_columns].values, df['future'].values):\n",
        "        sequences.append(entry)\n",
        "        if len(sequences) == n_steps:\n",
        "            sequence_data.append([np.array(sequences), target])\n",
        "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
        "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 59 (that is 50+10-1) length\n",
        "    # this last_sequence will be used to predict in future dates that are not available in the dataset\n",
        "    last_sequence = list(sequences) + list(last_sequence)\n",
        "    # shift the last sequence by -1\n",
        "    last_sequence = np.array(pd.DataFrame(last_sequence).shift(-1).dropna())\n",
        "    # add to result\n",
        "    result['last_sequence'] = last_sequence\n",
        "    # construct the X's and y's\n",
        "    X, y = [], []\n",
        "    for seq, target in sequence_data:\n",
        "        X.append(seq)\n",
        "        y.append(target)\n",
        "    # convert to numpy arrays\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    # reshape X to fit the neural network\n",
        "    X = X.reshape((X.shape[0], X.shape[2], X.shape[1]))\n",
        "    # split the dataset\n",
        "    result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, test_size=test_size, shuffle=shuffle)\n",
        "    # return the result\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JcTtrTgxJJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(sequence_length, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
        "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
        "    model = Sequential()\n",
        "    for i in range(n_layers):\n",
        "        if i == 0:\n",
        "            # first layer\n",
        "            if bidirectional:\n",
        "                model.add(Bidirectional(cell(units, return_sequences=True), input_shape=(None, sequence_length)))\n",
        "            else:\n",
        "                model.add(cell(units, return_sequences=True, input_shape=(None, sequence_length)))\n",
        "        elif i == n_layers - 1:\n",
        "            # last layer\n",
        "            if bidirectional:\n",
        "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
        "            else:\n",
        "                model.add(cell(units, return_sequences=False))\n",
        "        else:\n",
        "            # hidden layers\n",
        "            if bidirectional:\n",
        "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
        "            else:\n",
        "                model.add(cell(units, return_sequences=True))\n",
        "        # add dropout after each layer\n",
        "        model.add(Dropout(dropout))\n",
        "    model.add(Dense(1, activation=\"linear\"))\n",
        "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2PSoj_oyckh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Window size or the sequence length\n",
        "N_STEPS = 100\n",
        "# Lookup step, 1 is the next day\n",
        "LOOKUP_STEP = 50\n",
        "# test ratio size, 0.2 is 20%\n",
        "TEST_SIZE = 0.2\n",
        "# features to use\n",
        "FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
        "# date now\n",
        "date_now = time.strftime(\"%Y-%m-%d\")\n",
        "### model parameters\n",
        "N_LAYERS = 3\n",
        "# LSTM cell\n",
        "CELL = LSTM\n",
        "# 256 LSTM neurons\n",
        "UNITS = 256\n",
        "# 40% dropout\n",
        "DROPOUT = 0.4\n",
        "# whether to use bidirectional RNNs\n",
        "BIDIRECTIONAL = False\n",
        "### training parameters\n",
        "# mean absolute error loss\n",
        "# LOSS = \"mae\"\n",
        "# huber loss\n",
        "LOSS = \"huber_loss\"\n",
        "OPTIMIZER = \"adam\"\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 500\n",
        "# Apple stock market\n",
        "ticker = \"AAPL\"\n",
        "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
        "# model name to save, making it as unique as possible based on parameters\n",
        "model_name = f\"{date_now}_{ticker}-{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
        "if BIDIRECTIONAL:\n",
        "    model_name += \"-b\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xidCh9nFypcd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create these folders if they does not exist\n",
        "if not os.path.isdir(\"results\"):\n",
        "    os.mkdir(\"results\")\n",
        "if not os.path.isdir(\"logs\"):\n",
        "    os.mkdir(\"logs\")\n",
        "if not os.path.isdir(\"data\"):\n",
        "    os.mkdir(\"data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuRzHsSMy1RV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f97ee0db-de82-4414-f88d-f56d71ad2c74"
      },
      "source": [
        "# load the data\n",
        "data = load_data(ticker, N_STEPS, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, feature_columns=FEATURE_COLUMNS)\n",
        "\n",
        "# save the dataframe\n",
        "data[\"df\"].to_csv(ticker_data_filename)\n",
        "\n",
        "# construct the model\n",
        "model = create_model(N_STEPS, loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
        "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
        "\n",
        "# some tensorflow callbacks\n",
        "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
        "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
        "\n",
        "history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
        "                    callbacks=[checkpointer, tensorboard],\n",
        "                    verbose=1)\n",
        "\n",
        "model.save(os.path.join(\"results\", model_name) + \".h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 0.0012 - mean_absolute_error: 0.0214\n",
            "Epoch 00001: val_loss improved from inf to 0.00050, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 15s 118ms/step - loss: 0.0012 - mean_absolute_error: 0.0214 - val_loss: 4.9692e-04 - val_mean_absolute_error: 0.0138\n",
            "Epoch 2/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.1122e-04 - mean_absolute_error: 0.0170\n",
            "Epoch 00002: val_loss improved from 0.00050 to 0.00043, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 109ms/step - loss: 7.1122e-04 - mean_absolute_error: 0.0170 - val_loss: 4.3137e-04 - val_mean_absolute_error: 0.0125\n",
            "Epoch 3/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.4620e-04 - mean_absolute_error: 0.0166\n",
            "Epoch 00003: val_loss improved from 0.00043 to 0.00040, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 108ms/step - loss: 6.4620e-04 - mean_absolute_error: 0.0166 - val_loss: 4.0257e-04 - val_mean_absolute_error: 0.0123\n",
            "Epoch 4/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.4008e-04 - mean_absolute_error: 0.0178\n",
            "Epoch 00004: val_loss did not improve from 0.00040\n",
            "123/123 [==============================] - 13s 108ms/step - loss: 7.4008e-04 - mean_absolute_error: 0.0178 - val_loss: 4.2006e-04 - val_mean_absolute_error: 0.0126\n",
            "Epoch 5/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.1134e-04 - mean_absolute_error: 0.0177\n",
            "Epoch 00005: val_loss did not improve from 0.00040\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 7.1134e-04 - mean_absolute_error: 0.0177 - val_loss: 0.0011 - val_mean_absolute_error: 0.0198\n",
            "Epoch 6/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.3785e-04 - mean_absolute_error: 0.0171\n",
            "Epoch 00006: val_loss did not improve from 0.00040\n",
            "123/123 [==============================] - 14s 110ms/step - loss: 6.3785e-04 - mean_absolute_error: 0.0171 - val_loss: 5.2756e-04 - val_mean_absolute_error: 0.0161\n",
            "Epoch 7/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.0744e-04 - mean_absolute_error: 0.0163\n",
            "Epoch 00007: val_loss did not improve from 0.00040\n",
            "123/123 [==============================] - 14s 112ms/step - loss: 6.0744e-04 - mean_absolute_error: 0.0163 - val_loss: 6.6141e-04 - val_mean_absolute_error: 0.0194\n",
            "Epoch 8/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 5.8832e-04 - mean_absolute_error: 0.0161\n",
            "Epoch 00008: val_loss improved from 0.00040 to 0.00037, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 14s 110ms/step - loss: 5.8832e-04 - mean_absolute_error: 0.0161 - val_loss: 3.7249e-04 - val_mean_absolute_error: 0.0123\n",
            "Epoch 9/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 5.2091e-04 - mean_absolute_error: 0.0151\n",
            "Epoch 00009: val_loss did not improve from 0.00037\n",
            "123/123 [==============================] - 13s 109ms/step - loss: 5.2091e-04 - mean_absolute_error: 0.0151 - val_loss: 4.5869e-04 - val_mean_absolute_error: 0.0130\n",
            "Epoch 10/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 5.3871e-04 - mean_absolute_error: 0.0155\n",
            "Epoch 00010: val_loss did not improve from 0.00037\n",
            "123/123 [==============================] - 13s 109ms/step - loss: 5.3871e-04 - mean_absolute_error: 0.0155 - val_loss: 3.8402e-04 - val_mean_absolute_error: 0.0137\n",
            "Epoch 11/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 5.9265e-04 - mean_absolute_error: 0.0162\n",
            "Epoch 00011: val_loss did not improve from 0.00037\n",
            "123/123 [==============================] - 13s 109ms/step - loss: 5.9265e-04 - mean_absolute_error: 0.0162 - val_loss: 3.9791e-04 - val_mean_absolute_error: 0.0127\n",
            "Epoch 12/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 5.1213e-04 - mean_absolute_error: 0.0154\n",
            "Epoch 00012: val_loss did not improve from 0.00037\n",
            "123/123 [==============================] - 13s 109ms/step - loss: 5.1213e-04 - mean_absolute_error: 0.0154 - val_loss: 4.1887e-04 - val_mean_absolute_error: 0.0130\n",
            "Epoch 13/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 5.2940e-04 - mean_absolute_error: 0.0161\n",
            "Epoch 00013: val_loss did not improve from 0.00037\n",
            "123/123 [==============================] - 14s 110ms/step - loss: 5.2940e-04 - mean_absolute_error: 0.0161 - val_loss: 4.3891e-04 - val_mean_absolute_error: 0.0132\n",
            "Epoch 14/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 5.5269e-04 - mean_absolute_error: 0.0163\n",
            "Epoch 00014: val_loss did not improve from 0.00037\n",
            "123/123 [==============================] - 14s 110ms/step - loss: 5.5269e-04 - mean_absolute_error: 0.0163 - val_loss: 4.2838e-04 - val_mean_absolute_error: 0.0118\n",
            "Epoch 15/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 5.6067e-04 - mean_absolute_error: 0.0162\n",
            "Epoch 00015: val_loss did not improve from 0.00037\n",
            "123/123 [==============================] - 13s 109ms/step - loss: 5.6067e-04 - mean_absolute_error: 0.0162 - val_loss: 4.9161e-04 - val_mean_absolute_error: 0.0134\n",
            "Epoch 16/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 5.8061e-04 - mean_absolute_error: 0.0168\n",
            "Epoch 00016: val_loss did not improve from 0.00037\n",
            "123/123 [==============================] - 13s 109ms/step - loss: 5.8061e-04 - mean_absolute_error: 0.0168 - val_loss: 4.7152e-04 - val_mean_absolute_error: 0.0129\n",
            "Epoch 17/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 5.0052e-04 - mean_absolute_error: 0.0156\n",
            "Epoch 00017: val_loss improved from 0.00037 to 0.00034, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 109ms/step - loss: 5.0052e-04 - mean_absolute_error: 0.0156 - val_loss: 3.4406e-04 - val_mean_absolute_error: 0.0117\n",
            "Epoch 18/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 4.6929e-04 - mean_absolute_error: 0.0150\n",
            "Epoch 00018: val_loss did not improve from 0.00034\n",
            "123/123 [==============================] - 13s 109ms/step - loss: 4.6929e-04 - mean_absolute_error: 0.0150 - val_loss: 4.2620e-04 - val_mean_absolute_error: 0.0128\n",
            "Epoch 19/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 4.8760e-04 - mean_absolute_error: 0.0153\n",
            "Epoch 00019: val_loss did not improve from 0.00034\n",
            "123/123 [==============================] - 14s 110ms/step - loss: 4.8760e-04 - mean_absolute_error: 0.0153 - val_loss: 3.5633e-04 - val_mean_absolute_error: 0.0131\n",
            "Epoch 20/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 5.3360e-04 - mean_absolute_error: 0.0158\n",
            "Epoch 00020: val_loss did not improve from 0.00034\n",
            "123/123 [==============================] - 13s 108ms/step - loss: 5.3360e-04 - mean_absolute_error: 0.0158 - val_loss: 4.3482e-04 - val_mean_absolute_error: 0.0132\n",
            "Epoch 21/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 5.2828e-04 - mean_absolute_error: 0.0160\n",
            "Epoch 00021: val_loss did not improve from 0.00034\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 5.2828e-04 - mean_absolute_error: 0.0160 - val_loss: 4.7995e-04 - val_mean_absolute_error: 0.0122\n",
            "Epoch 22/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 5.0455e-04 - mean_absolute_error: 0.0155\n",
            "Epoch 00022: val_loss improved from 0.00034 to 0.00032, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 5.0455e-04 - mean_absolute_error: 0.0155 - val_loss: 3.1772e-04 - val_mean_absolute_error: 0.0117\n",
            "Epoch 23/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 4.4819e-04 - mean_absolute_error: 0.0144\n",
            "Epoch 00023: val_loss did not improve from 0.00032\n",
            "123/123 [==============================] - 13s 109ms/step - loss: 4.4819e-04 - mean_absolute_error: 0.0144 - val_loss: 4.1498e-04 - val_mean_absolute_error: 0.0118\n",
            "Epoch 24/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 4.2567e-04 - mean_absolute_error: 0.0145\n",
            "Epoch 00024: val_loss did not improve from 0.00032\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 4.2567e-04 - mean_absolute_error: 0.0145 - val_loss: 3.1808e-04 - val_mean_absolute_error: 0.0100\n",
            "Epoch 25/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 4.8254e-04 - mean_absolute_error: 0.0154\n",
            "Epoch 00025: val_loss did not improve from 0.00032\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 4.8254e-04 - mean_absolute_error: 0.0154 - val_loss: 4.8028e-04 - val_mean_absolute_error: 0.0167\n",
            "Epoch 26/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 5.4875e-04 - mean_absolute_error: 0.0163\n",
            "Epoch 00026: val_loss did not improve from 0.00032\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 5.4875e-04 - mean_absolute_error: 0.0163 - val_loss: 6.1423e-04 - val_mean_absolute_error: 0.0185\n",
            "Epoch 27/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 5.1497e-04 - mean_absolute_error: 0.0158\n",
            "Epoch 00027: val_loss did not improve from 0.00032\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 5.1497e-04 - mean_absolute_error: 0.0158 - val_loss: 3.2746e-04 - val_mean_absolute_error: 0.0098\n",
            "Epoch 28/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 4.3168e-04 - mean_absolute_error: 0.0146\n",
            "Epoch 00028: val_loss did not improve from 0.00032\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 4.3168e-04 - mean_absolute_error: 0.0146 - val_loss: 3.8515e-04 - val_mean_absolute_error: 0.0147\n",
            "Epoch 29/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 4.5420e-04 - mean_absolute_error: 0.0152\n",
            "Epoch 00029: val_loss improved from 0.00032 to 0.00030, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 108ms/step - loss: 4.5420e-04 - mean_absolute_error: 0.0152 - val_loss: 2.9927e-04 - val_mean_absolute_error: 0.0096\n",
            "Epoch 30/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 4.8630e-04 - mean_absolute_error: 0.0153\n",
            "Epoch 00030: val_loss improved from 0.00030 to 0.00029, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 14s 112ms/step - loss: 4.8630e-04 - mean_absolute_error: 0.0153 - val_loss: 2.9097e-04 - val_mean_absolute_error: 0.0094\n",
            "Epoch 31/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 4.4256e-04 - mean_absolute_error: 0.0146\n",
            "Epoch 00031: val_loss did not improve from 0.00029\n",
            "123/123 [==============================] - 13s 109ms/step - loss: 4.4256e-04 - mean_absolute_error: 0.0146 - val_loss: 3.9294e-04 - val_mean_absolute_error: 0.0116\n",
            "Epoch 32/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 4.8092e-04 - mean_absolute_error: 0.0154\n",
            "Epoch 00032: val_loss did not improve from 0.00029\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 4.8092e-04 - mean_absolute_error: 0.0154 - val_loss: 3.8776e-04 - val_mean_absolute_error: 0.0119\n",
            "Epoch 33/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 4.4883e-04 - mean_absolute_error: 0.0152\n",
            "Epoch 00033: val_loss did not improve from 0.00029\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 4.4883e-04 - mean_absolute_error: 0.0152 - val_loss: 3.0901e-04 - val_mean_absolute_error: 0.0102\n",
            "Epoch 34/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 4.4345e-04 - mean_absolute_error: 0.0150\n",
            "Epoch 00034: val_loss did not improve from 0.00029\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 4.4345e-04 - mean_absolute_error: 0.0150 - val_loss: 3.1006e-04 - val_mean_absolute_error: 0.0107\n",
            "Epoch 35/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 4.2350e-04 - mean_absolute_error: 0.0142\n",
            "Epoch 00035: val_loss improved from 0.00029 to 0.00027, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 108ms/step - loss: 4.2350e-04 - mean_absolute_error: 0.0142 - val_loss: 2.7410e-04 - val_mean_absolute_error: 0.0092\n",
            "Epoch 36/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 4.7347e-04 - mean_absolute_error: 0.0153\n",
            "Epoch 00036: val_loss did not improve from 0.00027\n",
            "123/123 [==============================] - 13s 108ms/step - loss: 4.7347e-04 - mean_absolute_error: 0.0153 - val_loss: 4.3845e-04 - val_mean_absolute_error: 0.0124\n",
            "Epoch 37/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 5.0011e-04 - mean_absolute_error: 0.0163\n",
            "Epoch 00037: val_loss did not improve from 0.00027\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 5.0011e-04 - mean_absolute_error: 0.0163 - val_loss: 4.2379e-04 - val_mean_absolute_error: 0.0182\n",
            "Epoch 38/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 4.3088e-04 - mean_absolute_error: 0.0149\n",
            "Epoch 00038: val_loss improved from 0.00027 to 0.00027, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 4.3088e-04 - mean_absolute_error: 0.0149 - val_loss: 2.7261e-04 - val_mean_absolute_error: 0.0096\n",
            "Epoch 39/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 4.2340e-04 - mean_absolute_error: 0.0146\n",
            "Epoch 00039: val_loss did not improve from 0.00027\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 4.2340e-04 - mean_absolute_error: 0.0146 - val_loss: 4.3958e-04 - val_mean_absolute_error: 0.0128\n",
            "Epoch 40/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 4.0716e-04 - mean_absolute_error: 0.0141\n",
            "Epoch 00040: val_loss did not improve from 0.00027\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 4.0716e-04 - mean_absolute_error: 0.0141 - val_loss: 3.1812e-04 - val_mean_absolute_error: 0.0098\n",
            "Epoch 41/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 3.9857e-04 - mean_absolute_error: 0.0139\n",
            "Epoch 00041: val_loss did not improve from 0.00027\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 3.9857e-04 - mean_absolute_error: 0.0139 - val_loss: 3.3225e-04 - val_mean_absolute_error: 0.0115\n",
            "Epoch 42/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 3.8038e-04 - mean_absolute_error: 0.0136\n",
            "Epoch 00042: val_loss improved from 0.00027 to 0.00026, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 3.8038e-04 - mean_absolute_error: 0.0136 - val_loss: 2.6453e-04 - val_mean_absolute_error: 0.0097\n",
            "Epoch 43/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 4.1949e-04 - mean_absolute_error: 0.0143\n",
            "Epoch 00043: val_loss did not improve from 0.00026\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 4.1949e-04 - mean_absolute_error: 0.0143 - val_loss: 2.7154e-04 - val_mean_absolute_error: 0.0113\n",
            "Epoch 44/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 4.0558e-04 - mean_absolute_error: 0.0145\n",
            "Epoch 00044: val_loss did not improve from 0.00026\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 4.0558e-04 - mean_absolute_error: 0.0145 - val_loss: 3.2036e-04 - val_mean_absolute_error: 0.0130\n",
            "Epoch 45/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 3.8983e-04 - mean_absolute_error: 0.0139\n",
            "Epoch 00045: val_loss did not improve from 0.00026\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 3.8983e-04 - mean_absolute_error: 0.0139 - val_loss: 2.9820e-04 - val_mean_absolute_error: 0.0122\n",
            "Epoch 46/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 3.9362e-04 - mean_absolute_error: 0.0138\n",
            "Epoch 00046: val_loss did not improve from 0.00026\n",
            "123/123 [==============================] - 13s 108ms/step - loss: 3.9362e-04 - mean_absolute_error: 0.0138 - val_loss: 2.9490e-04 - val_mean_absolute_error: 0.0103\n",
            "Epoch 47/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 3.8758e-04 - mean_absolute_error: 0.0138\n",
            "Epoch 00047: val_loss did not improve from 0.00026\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 3.8758e-04 - mean_absolute_error: 0.0138 - val_loss: 2.6580e-04 - val_mean_absolute_error: 0.0093\n",
            "Epoch 48/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 4.0062e-04 - mean_absolute_error: 0.0136\n",
            "Epoch 00048: val_loss did not improve from 0.00026\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 4.0062e-04 - mean_absolute_error: 0.0136 - val_loss: 3.7061e-04 - val_mean_absolute_error: 0.0105\n",
            "Epoch 49/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 3.9044e-04 - mean_absolute_error: 0.0142\n",
            "Epoch 00049: val_loss improved from 0.00026 to 0.00026, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 3.9044e-04 - mean_absolute_error: 0.0142 - val_loss: 2.6074e-04 - val_mean_absolute_error: 0.0108\n",
            "Epoch 50/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 3.8938e-04 - mean_absolute_error: 0.0140\n",
            "Epoch 00050: val_loss did not improve from 0.00026\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 3.8938e-04 - mean_absolute_error: 0.0140 - val_loss: 2.7264e-04 - val_mean_absolute_error: 0.0095\n",
            "Epoch 51/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 3.8426e-04 - mean_absolute_error: 0.0139\n",
            "Epoch 00051: val_loss did not improve from 0.00026\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 3.8426e-04 - mean_absolute_error: 0.0139 - val_loss: 2.8229e-04 - val_mean_absolute_error: 0.0095\n",
            "Epoch 52/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 3.7356e-04 - mean_absolute_error: 0.0136\n",
            "Epoch 00052: val_loss did not improve from 0.00026\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 3.7356e-04 - mean_absolute_error: 0.0136 - val_loss: 2.6132e-04 - val_mean_absolute_error: 0.0090\n",
            "Epoch 53/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 4.0419e-04 - mean_absolute_error: 0.0140\n",
            "Epoch 00053: val_loss did not improve from 0.00026\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 4.0419e-04 - mean_absolute_error: 0.0140 - val_loss: 2.9494e-04 - val_mean_absolute_error: 0.0110\n",
            "Epoch 54/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 3.6972e-04 - mean_absolute_error: 0.0139\n",
            "Epoch 00054: val_loss improved from 0.00026 to 0.00026, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 109ms/step - loss: 3.6972e-04 - mean_absolute_error: 0.0139 - val_loss: 2.5879e-04 - val_mean_absolute_error: 0.0110\n",
            "Epoch 55/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 3.6662e-04 - mean_absolute_error: 0.0135\n",
            "Epoch 00055: val_loss did not improve from 0.00026\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 3.6662e-04 - mean_absolute_error: 0.0135 - val_loss: 2.8260e-04 - val_mean_absolute_error: 0.0119\n",
            "Epoch 56/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 3.5211e-04 - mean_absolute_error: 0.0131\n",
            "Epoch 00056: val_loss did not improve from 0.00026\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 3.5211e-04 - mean_absolute_error: 0.0131 - val_loss: 3.2814e-04 - val_mean_absolute_error: 0.0100\n",
            "Epoch 57/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 3.5101e-04 - mean_absolute_error: 0.0135\n",
            "Epoch 00057: val_loss did not improve from 0.00026\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 3.5101e-04 - mean_absolute_error: 0.0135 - val_loss: 3.7440e-04 - val_mean_absolute_error: 0.0129\n",
            "Epoch 58/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 3.5815e-04 - mean_absolute_error: 0.0137\n",
            "Epoch 00058: val_loss did not improve from 0.00026\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 3.5815e-04 - mean_absolute_error: 0.0137 - val_loss: 2.8892e-04 - val_mean_absolute_error: 0.0101\n",
            "Epoch 59/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 3.4503e-04 - mean_absolute_error: 0.0136\n",
            "Epoch 00059: val_loss did not improve from 0.00026\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 3.4503e-04 - mean_absolute_error: 0.0136 - val_loss: 2.6935e-04 - val_mean_absolute_error: 0.0093\n",
            "Epoch 60/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 3.6347e-04 - mean_absolute_error: 0.0135\n",
            "Epoch 00060: val_loss did not improve from 0.00026\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 3.6347e-04 - mean_absolute_error: 0.0135 - val_loss: 3.4215e-04 - val_mean_absolute_error: 0.0130\n",
            "Epoch 61/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 3.4348e-04 - mean_absolute_error: 0.0131\n",
            "Epoch 00061: val_loss improved from 0.00026 to 0.00026, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 3.4348e-04 - mean_absolute_error: 0.0131 - val_loss: 2.5563e-04 - val_mean_absolute_error: 0.0092\n",
            "Epoch 62/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 3.6539e-04 - mean_absolute_error: 0.0138\n",
            "Epoch 00062: val_loss improved from 0.00026 to 0.00025, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 3.6539e-04 - mean_absolute_error: 0.0138 - val_loss: 2.4634e-04 - val_mean_absolute_error: 0.0093\n",
            "Epoch 63/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 3.3885e-04 - mean_absolute_error: 0.0133\n",
            "Epoch 00063: val_loss did not improve from 0.00025\n",
            "123/123 [==============================] - 13s 108ms/step - loss: 3.3885e-04 - mean_absolute_error: 0.0133 - val_loss: 2.7098e-04 - val_mean_absolute_error: 0.0112\n",
            "Epoch 64/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 3.4754e-04 - mean_absolute_error: 0.0137\n",
            "Epoch 00064: val_loss did not improve from 0.00025\n",
            "123/123 [==============================] - 13s 108ms/step - loss: 3.4754e-04 - mean_absolute_error: 0.0137 - val_loss: 2.5668e-04 - val_mean_absolute_error: 0.0097\n",
            "Epoch 65/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 3.1541e-04 - mean_absolute_error: 0.0130\n",
            "Epoch 00065: val_loss improved from 0.00025 to 0.00021, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 108ms/step - loss: 3.1541e-04 - mean_absolute_error: 0.0130 - val_loss: 2.0917e-04 - val_mean_absolute_error: 0.0098\n",
            "Epoch 66/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 3.3959e-04 - mean_absolute_error: 0.0132\n",
            "Epoch 00066: val_loss did not improve from 0.00021\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 3.3959e-04 - mean_absolute_error: 0.0132 - val_loss: 3.4855e-04 - val_mean_absolute_error: 0.0110\n",
            "Epoch 67/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 3.6749e-04 - mean_absolute_error: 0.0137\n",
            "Epoch 00067: val_loss did not improve from 0.00021\n",
            "123/123 [==============================] - 13s 108ms/step - loss: 3.6749e-04 - mean_absolute_error: 0.0137 - val_loss: 2.2797e-04 - val_mean_absolute_error: 0.0106\n",
            "Epoch 68/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 3.1686e-04 - mean_absolute_error: 0.0127\n",
            "Epoch 00068: val_loss did not improve from 0.00021\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 3.1686e-04 - mean_absolute_error: 0.0127 - val_loss: 2.2630e-04 - val_mean_absolute_error: 0.0101\n",
            "Epoch 69/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 3.2681e-04 - mean_absolute_error: 0.0130\n",
            "Epoch 00069: val_loss did not improve from 0.00021\n",
            "123/123 [==============================] - 13s 109ms/step - loss: 3.2681e-04 - mean_absolute_error: 0.0130 - val_loss: 2.1113e-04 - val_mean_absolute_error: 0.0086\n",
            "Epoch 70/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 3.4655e-04 - mean_absolute_error: 0.0133\n",
            "Epoch 00070: val_loss improved from 0.00021 to 0.00020, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 3.4655e-04 - mean_absolute_error: 0.0133 - val_loss: 2.0434e-04 - val_mean_absolute_error: 0.0097\n",
            "Epoch 71/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.7617e-04 - mean_absolute_error: 0.0125\n",
            "Epoch 00071: val_loss improved from 0.00020 to 0.00018, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 108ms/step - loss: 2.7617e-04 - mean_absolute_error: 0.0125 - val_loss: 1.7537e-04 - val_mean_absolute_error: 0.0089\n",
            "Epoch 72/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 3.1574e-04 - mean_absolute_error: 0.0127\n",
            "Epoch 00072: val_loss did not improve from 0.00018\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 3.1574e-04 - mean_absolute_error: 0.0127 - val_loss: 2.3625e-04 - val_mean_absolute_error: 0.0122\n",
            "Epoch 73/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 3.1225e-04 - mean_absolute_error: 0.0129\n",
            "Epoch 00073: val_loss did not improve from 0.00018\n",
            "123/123 [==============================] - 13s 108ms/step - loss: 3.1225e-04 - mean_absolute_error: 0.0129 - val_loss: 2.2339e-04 - val_mean_absolute_error: 0.0113\n",
            "Epoch 74/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.8972e-04 - mean_absolute_error: 0.0125\n",
            "Epoch 00074: val_loss did not improve from 0.00018\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 2.8972e-04 - mean_absolute_error: 0.0125 - val_loss: 2.1817e-04 - val_mean_absolute_error: 0.0096\n",
            "Epoch 75/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 3.2244e-04 - mean_absolute_error: 0.0138\n",
            "Epoch 00075: val_loss did not improve from 0.00018\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 3.2244e-04 - mean_absolute_error: 0.0138 - val_loss: 1.7832e-04 - val_mean_absolute_error: 0.0087\n",
            "Epoch 76/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.3090e-04 - mean_absolute_error: 0.0116\n",
            "Epoch 00076: val_loss improved from 0.00018 to 0.00016, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 2.3090e-04 - mean_absolute_error: 0.0116 - val_loss: 1.6057e-04 - val_mean_absolute_error: 0.0083\n",
            "Epoch 77/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.3493e-04 - mean_absolute_error: 0.0119\n",
            "Epoch 00077: val_loss improved from 0.00016 to 0.00016, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 108ms/step - loss: 2.3493e-04 - mean_absolute_error: 0.0119 - val_loss: 1.5967e-04 - val_mean_absolute_error: 0.0081\n",
            "Epoch 78/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.5800e-04 - mean_absolute_error: 0.0124\n",
            "Epoch 00078: val_loss did not improve from 0.00016\n",
            "123/123 [==============================] - 14s 110ms/step - loss: 2.5800e-04 - mean_absolute_error: 0.0124 - val_loss: 3.0380e-04 - val_mean_absolute_error: 0.0133\n",
            "Epoch 79/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.6871e-04 - mean_absolute_error: 0.0121\n",
            "Epoch 00079: val_loss did not improve from 0.00016\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 2.6871e-04 - mean_absolute_error: 0.0121 - val_loss: 2.9313e-04 - val_mean_absolute_error: 0.0094\n",
            "Epoch 80/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.8619e-04 - mean_absolute_error: 0.0129\n",
            "Epoch 00080: val_loss did not improve from 0.00016\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 2.8619e-04 - mean_absolute_error: 0.0129 - val_loss: 1.9518e-04 - val_mean_absolute_error: 0.0100\n",
            "Epoch 81/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.8262e-04 - mean_absolute_error: 0.0125\n",
            "Epoch 00081: val_loss did not improve from 0.00016\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 2.8262e-04 - mean_absolute_error: 0.0125 - val_loss: 1.7175e-04 - val_mean_absolute_error: 0.0108\n",
            "Epoch 82/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.7673e-04 - mean_absolute_error: 0.0126\n",
            "Epoch 00082: val_loss did not improve from 0.00016\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 2.7673e-04 - mean_absolute_error: 0.0126 - val_loss: 2.9003e-04 - val_mean_absolute_error: 0.0111\n",
            "Epoch 83/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 3.1096e-04 - mean_absolute_error: 0.0131\n",
            "Epoch 00083: val_loss improved from 0.00016 to 0.00012, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 3.1096e-04 - mean_absolute_error: 0.0131 - val_loss: 1.2285e-04 - val_mean_absolute_error: 0.0080\n",
            "Epoch 84/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.6167e-04 - mean_absolute_error: 0.0122\n",
            "Epoch 00084: val_loss did not improve from 0.00012\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 2.6167e-04 - mean_absolute_error: 0.0122 - val_loss: 2.7326e-04 - val_mean_absolute_error: 0.0086\n",
            "Epoch 85/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.8101e-04 - mean_absolute_error: 0.0127\n",
            "Epoch 00085: val_loss did not improve from 0.00012\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 2.8101e-04 - mean_absolute_error: 0.0127 - val_loss: 1.8621e-04 - val_mean_absolute_error: 0.0082\n",
            "Epoch 86/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.2814e-04 - mean_absolute_error: 0.0117\n",
            "Epoch 00086: val_loss did not improve from 0.00012\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 2.2814e-04 - mean_absolute_error: 0.0117 - val_loss: 1.3937e-04 - val_mean_absolute_error: 0.0089\n",
            "Epoch 87/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.2193e-04 - mean_absolute_error: 0.0116\n",
            "Epoch 00087: val_loss did not improve from 0.00012\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 2.2193e-04 - mean_absolute_error: 0.0116 - val_loss: 1.9678e-04 - val_mean_absolute_error: 0.0091\n",
            "Epoch 88/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.2034e-04 - mean_absolute_error: 0.0114\n",
            "Epoch 00088: val_loss did not improve from 0.00012\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 2.2034e-04 - mean_absolute_error: 0.0114 - val_loss: 1.3995e-04 - val_mean_absolute_error: 0.0088\n",
            "Epoch 89/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.8712e-04 - mean_absolute_error: 0.0110\n",
            "Epoch 00089: val_loss did not improve from 0.00012\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 1.8712e-04 - mean_absolute_error: 0.0110 - val_loss: 1.2608e-04 - val_mean_absolute_error: 0.0075\n",
            "Epoch 90/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.1432e-04 - mean_absolute_error: 0.0112\n",
            "Epoch 00090: val_loss did not improve from 0.00012\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 2.1432e-04 - mean_absolute_error: 0.0112 - val_loss: 2.1287e-04 - val_mean_absolute_error: 0.0082\n",
            "Epoch 91/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.1685e-04 - mean_absolute_error: 0.0114\n",
            "Epoch 00091: val_loss improved from 0.00012 to 0.00009, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 2.1685e-04 - mean_absolute_error: 0.0114 - val_loss: 9.0160e-05 - val_mean_absolute_error: 0.0068\n",
            "Epoch 92/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.0298e-04 - mean_absolute_error: 0.0112\n",
            "Epoch 00092: val_loss improved from 0.00009 to 0.00008, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 2.0298e-04 - mean_absolute_error: 0.0112 - val_loss: 8.0673e-05 - val_mean_absolute_error: 0.0065\n",
            "Epoch 93/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.0883e-04 - mean_absolute_error: 0.0110\n",
            "Epoch 00093: val_loss did not improve from 0.00008\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 2.0883e-04 - mean_absolute_error: 0.0110 - val_loss: 1.2002e-04 - val_mean_absolute_error: 0.0083\n",
            "Epoch 94/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.8090e-04 - mean_absolute_error: 0.0112\n",
            "Epoch 00094: val_loss did not improve from 0.00008\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.8090e-04 - mean_absolute_error: 0.0112 - val_loss: 1.1172e-04 - val_mean_absolute_error: 0.0098\n",
            "Epoch 95/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.8204e-04 - mean_absolute_error: 0.0109\n",
            "Epoch 00095: val_loss did not improve from 0.00008\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.8204e-04 - mean_absolute_error: 0.0109 - val_loss: 9.2958e-05 - val_mean_absolute_error: 0.0079\n",
            "Epoch 96/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.8392e-04 - mean_absolute_error: 0.0110\n",
            "Epoch 00096: val_loss did not improve from 0.00008\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.8392e-04 - mean_absolute_error: 0.0110 - val_loss: 8.6762e-05 - val_mean_absolute_error: 0.0080\n",
            "Epoch 97/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.6091e-04 - mean_absolute_error: 0.0104\n",
            "Epoch 00097: val_loss did not improve from 0.00008\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 1.6091e-04 - mean_absolute_error: 0.0104 - val_loss: 9.8454e-05 - val_mean_absolute_error: 0.0088\n",
            "Epoch 98/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.1041e-04 - mean_absolute_error: 0.0111\n",
            "Epoch 00098: val_loss did not improve from 0.00008\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 2.1041e-04 - mean_absolute_error: 0.0111 - val_loss: 2.5632e-04 - val_mean_absolute_error: 0.0093\n",
            "Epoch 99/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.7545e-04 - mean_absolute_error: 0.0108\n",
            "Epoch 00099: val_loss did not improve from 0.00008\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 1.7545e-04 - mean_absolute_error: 0.0108 - val_loss: 8.7567e-05 - val_mean_absolute_error: 0.0064\n",
            "Epoch 100/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.1444e-04 - mean_absolute_error: 0.0115\n",
            "Epoch 00100: val_loss did not improve from 0.00008\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 2.1444e-04 - mean_absolute_error: 0.0115 - val_loss: 1.6819e-04 - val_mean_absolute_error: 0.0088\n",
            "Epoch 101/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.1064e-04 - mean_absolute_error: 0.0112\n",
            "Epoch 00101: val_loss improved from 0.00008 to 0.00008, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 2.1064e-04 - mean_absolute_error: 0.0112 - val_loss: 7.5953e-05 - val_mean_absolute_error: 0.0063\n",
            "Epoch 102/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.1350e-04 - mean_absolute_error: 0.0114\n",
            "Epoch 00102: val_loss did not improve from 0.00008\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 2.1350e-04 - mean_absolute_error: 0.0114 - val_loss: 1.5618e-04 - val_mean_absolute_error: 0.0087\n",
            "Epoch 103/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.0165e-04 - mean_absolute_error: 0.0110\n",
            "Epoch 00103: val_loss did not improve from 0.00008\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 2.0165e-04 - mean_absolute_error: 0.0110 - val_loss: 8.8993e-05 - val_mean_absolute_error: 0.0085\n",
            "Epoch 104/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.5813e-04 - mean_absolute_error: 0.0105\n",
            "Epoch 00104: val_loss did not improve from 0.00008\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 1.5813e-04 - mean_absolute_error: 0.0105 - val_loss: 8.2157e-05 - val_mean_absolute_error: 0.0066\n",
            "Epoch 105/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.8458e-04 - mean_absolute_error: 0.0108\n",
            "Epoch 00105: val_loss did not improve from 0.00008\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 1.8458e-04 - mean_absolute_error: 0.0108 - val_loss: 1.2868e-04 - val_mean_absolute_error: 0.0088\n",
            "Epoch 106/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.6205e-04 - mean_absolute_error: 0.0104\n",
            "Epoch 00106: val_loss did not improve from 0.00008\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.6205e-04 - mean_absolute_error: 0.0104 - val_loss: 1.3509e-04 - val_mean_absolute_error: 0.0079\n",
            "Epoch 107/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.5760e-04 - mean_absolute_error: 0.0116\n",
            "Epoch 00107: val_loss did not improve from 0.00008\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 2.5760e-04 - mean_absolute_error: 0.0116 - val_loss: 1.4375e-04 - val_mean_absolute_error: 0.0088\n",
            "Epoch 108/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.6304e-04 - mean_absolute_error: 0.0103\n",
            "Epoch 00108: val_loss did not improve from 0.00008\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.6304e-04 - mean_absolute_error: 0.0103 - val_loss: 8.1500e-05 - val_mean_absolute_error: 0.0081\n",
            "Epoch 109/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.5583e-04 - mean_absolute_error: 0.0102\n",
            "Epoch 00109: val_loss did not improve from 0.00008\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 1.5583e-04 - mean_absolute_error: 0.0102 - val_loss: 1.0547e-04 - val_mean_absolute_error: 0.0091\n",
            "Epoch 110/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.5877e-04 - mean_absolute_error: 0.0101\n",
            "Epoch 00110: val_loss improved from 0.00008 to 0.00007, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 1.5877e-04 - mean_absolute_error: 0.0101 - val_loss: 7.0981e-05 - val_mean_absolute_error: 0.0060\n",
            "Epoch 111/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.0597e-04 - mean_absolute_error: 0.0109\n",
            "Epoch 00111: val_loss did not improve from 0.00007\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 2.0597e-04 - mean_absolute_error: 0.0109 - val_loss: 3.5314e-04 - val_mean_absolute_error: 0.0143\n",
            "Epoch 112/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.1732e-04 - mean_absolute_error: 0.0113\n",
            "Epoch 00112: val_loss did not improve from 0.00007\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 2.1732e-04 - mean_absolute_error: 0.0113 - val_loss: 1.1025e-04 - val_mean_absolute_error: 0.0069\n",
            "Epoch 113/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.6362e-04 - mean_absolute_error: 0.0101\n",
            "Epoch 00113: val_loss did not improve from 0.00007\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 1.6362e-04 - mean_absolute_error: 0.0101 - val_loss: 3.0006e-04 - val_mean_absolute_error: 0.0093\n",
            "Epoch 114/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.8403e-04 - mean_absolute_error: 0.0103\n",
            "Epoch 00114: val_loss did not improve from 0.00007\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.8403e-04 - mean_absolute_error: 0.0103 - val_loss: 9.3400e-05 - val_mean_absolute_error: 0.0070\n",
            "Epoch 115/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.4178e-04 - mean_absolute_error: 0.0099\n",
            "Epoch 00115: val_loss improved from 0.00007 to 0.00007, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 1.4178e-04 - mean_absolute_error: 0.0099 - val_loss: 6.7064e-05 - val_mean_absolute_error: 0.0084\n",
            "Epoch 116/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.4151e-04 - mean_absolute_error: 0.0098\n",
            "Epoch 00116: val_loss did not improve from 0.00007\n",
            "123/123 [==============================] - 13s 108ms/step - loss: 1.4151e-04 - mean_absolute_error: 0.0098 - val_loss: 7.8133e-05 - val_mean_absolute_error: 0.0059\n",
            "Epoch 117/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.4231e-04 - mean_absolute_error: 0.0098\n",
            "Epoch 00117: val_loss did not improve from 0.00007\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 1.4231e-04 - mean_absolute_error: 0.0098 - val_loss: 7.3249e-05 - val_mean_absolute_error: 0.0066\n",
            "Epoch 118/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.3648e-04 - mean_absolute_error: 0.0096\n",
            "Epoch 00118: val_loss did not improve from 0.00007\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.3648e-04 - mean_absolute_error: 0.0096 - val_loss: 1.0153e-04 - val_mean_absolute_error: 0.0063\n",
            "Epoch 119/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.6753e-04 - mean_absolute_error: 0.0103\n",
            "Epoch 00119: val_loss improved from 0.00007 to 0.00006, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 1.6753e-04 - mean_absolute_error: 0.0103 - val_loss: 6.0452e-05 - val_mean_absolute_error: 0.0058\n",
            "Epoch 120/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.5125e-04 - mean_absolute_error: 0.0098\n",
            "Epoch 00120: val_loss did not improve from 0.00006\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.5125e-04 - mean_absolute_error: 0.0098 - val_loss: 1.3715e-04 - val_mean_absolute_error: 0.0074\n",
            "Epoch 121/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.7912e-04 - mean_absolute_error: 0.0103\n",
            "Epoch 00121: val_loss did not improve from 0.00006\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 1.7912e-04 - mean_absolute_error: 0.0103 - val_loss: 6.1299e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 122/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.6665e-04 - mean_absolute_error: 0.0103\n",
            "Epoch 00122: val_loss improved from 0.00006 to 0.00006, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 108ms/step - loss: 1.6665e-04 - mean_absolute_error: 0.0103 - val_loss: 5.6656e-05 - val_mean_absolute_error: 0.0071\n",
            "Epoch 123/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.6415e-04 - mean_absolute_error: 0.0100\n",
            "Epoch 00123: val_loss did not improve from 0.00006\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.6415e-04 - mean_absolute_error: 0.0100 - val_loss: 1.5591e-04 - val_mean_absolute_error: 0.0093\n",
            "Epoch 124/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.5666e-04 - mean_absolute_error: 0.0100\n",
            "Epoch 00124: val_loss did not improve from 0.00006\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.5666e-04 - mean_absolute_error: 0.0100 - val_loss: 9.3758e-05 - val_mean_absolute_error: 0.0072\n",
            "Epoch 125/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.4365e-04 - mean_absolute_error: 0.0099\n",
            "Epoch 00125: val_loss did not improve from 0.00006\n",
            "123/123 [==============================] - 13s 108ms/step - loss: 1.4365e-04 - mean_absolute_error: 0.0099 - val_loss: 7.4316e-05 - val_mean_absolute_error: 0.0063\n",
            "Epoch 126/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.4434e-04 - mean_absolute_error: 0.0097\n",
            "Epoch 00126: val_loss improved from 0.00006 to 0.00005, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 108ms/step - loss: 1.4434e-04 - mean_absolute_error: 0.0097 - val_loss: 4.7888e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 127/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.3767e-04 - mean_absolute_error: 0.0096\n",
            "Epoch 00127: val_loss did not improve from 0.00005\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.3767e-04 - mean_absolute_error: 0.0096 - val_loss: 8.6047e-05 - val_mean_absolute_error: 0.0066\n",
            "Epoch 128/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.3892e-04 - mean_absolute_error: 0.0094\n",
            "Epoch 00128: val_loss did not improve from 0.00005\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.3892e-04 - mean_absolute_error: 0.0094 - val_loss: 7.1175e-05 - val_mean_absolute_error: 0.0059\n",
            "Epoch 129/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.6082e-04 - mean_absolute_error: 0.0099\n",
            "Epoch 00129: val_loss did not improve from 0.00005\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.6082e-04 - mean_absolute_error: 0.0099 - val_loss: 6.1159e-05 - val_mean_absolute_error: 0.0059\n",
            "Epoch 130/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.4648e-04 - mean_absolute_error: 0.0098\n",
            "Epoch 00130: val_loss did not improve from 0.00005\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.4648e-04 - mean_absolute_error: 0.0098 - val_loss: 5.5150e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 131/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.5141e-04 - mean_absolute_error: 0.0097\n",
            "Epoch 00131: val_loss did not improve from 0.00005\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 1.5141e-04 - mean_absolute_error: 0.0097 - val_loss: 8.0738e-05 - val_mean_absolute_error: 0.0076\n",
            "Epoch 132/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.3208e-04 - mean_absolute_error: 0.0096\n",
            "Epoch 00132: val_loss did not improve from 0.00005\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.3208e-04 - mean_absolute_error: 0.0096 - val_loss: 7.0582e-05 - val_mean_absolute_error: 0.0073\n",
            "Epoch 133/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.3810e-04 - mean_absolute_error: 0.0095\n",
            "Epoch 00133: val_loss did not improve from 0.00005\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 1.3810e-04 - mean_absolute_error: 0.0095 - val_loss: 5.6018e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 134/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.3400e-04 - mean_absolute_error: 0.0095\n",
            "Epoch 00134: val_loss did not improve from 0.00005\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 1.3400e-04 - mean_absolute_error: 0.0095 - val_loss: 6.9640e-05 - val_mean_absolute_error: 0.0062\n",
            "Epoch 135/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.2537e-04 - mean_absolute_error: 0.0092\n",
            "Epoch 00135: val_loss improved from 0.00005 to 0.00005, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 1.2537e-04 - mean_absolute_error: 0.0092 - val_loss: 4.7463e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 136/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.3754e-04 - mean_absolute_error: 0.0095\n",
            "Epoch 00136: val_loss did not improve from 0.00005\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.3754e-04 - mean_absolute_error: 0.0095 - val_loss: 5.8248e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 137/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.2105e-04 - mean_absolute_error: 0.0092\n",
            "Epoch 00137: val_loss did not improve from 0.00005\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 1.2105e-04 - mean_absolute_error: 0.0092 - val_loss: 8.5327e-05 - val_mean_absolute_error: 0.0066\n",
            "Epoch 138/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.2006e-04 - mean_absolute_error: 0.0091\n",
            "Epoch 00138: val_loss did not improve from 0.00005\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 1.2006e-04 - mean_absolute_error: 0.0091 - val_loss: 5.8158e-05 - val_mean_absolute_error: 0.0059\n",
            "Epoch 139/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.3931e-04 - mean_absolute_error: 0.0094\n",
            "Epoch 00139: val_loss did not improve from 0.00005\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.3931e-04 - mean_absolute_error: 0.0094 - val_loss: 1.2903e-04 - val_mean_absolute_error: 0.0079\n",
            "Epoch 140/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.3839e-04 - mean_absolute_error: 0.0096\n",
            "Epoch 00140: val_loss did not improve from 0.00005\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 1.3839e-04 - mean_absolute_error: 0.0096 - val_loss: 6.6006e-05 - val_mean_absolute_error: 0.0070\n",
            "Epoch 141/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.5702e-04 - mean_absolute_error: 0.0096\n",
            "Epoch 00141: val_loss did not improve from 0.00005\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 1.5702e-04 - mean_absolute_error: 0.0096 - val_loss: 6.0736e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 142/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.1771e-04 - mean_absolute_error: 0.0092\n",
            "Epoch 00142: val_loss did not improve from 0.00005\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 1.1771e-04 - mean_absolute_error: 0.0092 - val_loss: 7.2688e-05 - val_mean_absolute_error: 0.0063\n",
            "Epoch 143/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.2012e-04 - mean_absolute_error: 0.0092\n",
            "Epoch 00143: val_loss did not improve from 0.00005\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 1.2012e-04 - mean_absolute_error: 0.0092 - val_loss: 5.2124e-05 - val_mean_absolute_error: 0.0066\n",
            "Epoch 144/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.7703e-04 - mean_absolute_error: 0.0102\n",
            "Epoch 00144: val_loss did not improve from 0.00005\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.7703e-04 - mean_absolute_error: 0.0102 - val_loss: 6.1024e-05 - val_mean_absolute_error: 0.0062\n",
            "Epoch 145/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.2553e-04 - mean_absolute_error: 0.0093\n",
            "Epoch 00145: val_loss improved from 0.00005 to 0.00004, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.2553e-04 - mean_absolute_error: 0.0093 - val_loss: 3.7174e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 146/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.1415e-04 - mean_absolute_error: 0.0089\n",
            "Epoch 00146: val_loss did not improve from 0.00004\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.1415e-04 - mean_absolute_error: 0.0089 - val_loss: 4.4052e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 147/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.0617e-04 - mean_absolute_error: 0.0088\n",
            "Epoch 00147: val_loss did not improve from 0.00004\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.0617e-04 - mean_absolute_error: 0.0088 - val_loss: 9.4446e-05 - val_mean_absolute_error: 0.0064\n",
            "Epoch 148/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.2450e-04 - mean_absolute_error: 0.0092\n",
            "Epoch 00148: val_loss did not improve from 0.00004\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 1.2450e-04 - mean_absolute_error: 0.0092 - val_loss: 4.7996e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 149/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.1463e-04 - mean_absolute_error: 0.0089\n",
            "Epoch 00149: val_loss did not improve from 0.00004\n",
            "123/123 [==============================] - 14s 110ms/step - loss: 1.1463e-04 - mean_absolute_error: 0.0089 - val_loss: 4.6393e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 150/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.0662e-04 - mean_absolute_error: 0.0086\n",
            "Epoch 00150: val_loss did not improve from 0.00004\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 1.0662e-04 - mean_absolute_error: 0.0086 - val_loss: 7.3386e-05 - val_mean_absolute_error: 0.0069\n",
            "Epoch 151/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.4435e-04 - mean_absolute_error: 0.0096\n",
            "Epoch 00151: val_loss did not improve from 0.00004\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 1.4435e-04 - mean_absolute_error: 0.0096 - val_loss: 4.9554e-05 - val_mean_absolute_error: 0.0061\n",
            "Epoch 152/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.2658e-04 - mean_absolute_error: 0.0092\n",
            "Epoch 00152: val_loss did not improve from 0.00004\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.2658e-04 - mean_absolute_error: 0.0092 - val_loss: 6.8291e-05 - val_mean_absolute_error: 0.0061\n",
            "Epoch 153/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.1956e-04 - mean_absolute_error: 0.0091\n",
            "Epoch 00153: val_loss did not improve from 0.00004\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 1.1956e-04 - mean_absolute_error: 0.0091 - val_loss: 6.6276e-05 - val_mean_absolute_error: 0.0058\n",
            "Epoch 154/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.1498e-04 - mean_absolute_error: 0.0090\n",
            "Epoch 00154: val_loss did not improve from 0.00004\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 1.1498e-04 - mean_absolute_error: 0.0090 - val_loss: 7.0180e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 155/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.6721e-04 - mean_absolute_error: 0.0100\n",
            "Epoch 00155: val_loss did not improve from 0.00004\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.6721e-04 - mean_absolute_error: 0.0100 - val_loss: 6.1318e-05 - val_mean_absolute_error: 0.0059\n",
            "Epoch 156/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.4965e-04 - mean_absolute_error: 0.0095\n",
            "Epoch 00156: val_loss did not improve from 0.00004\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 1.4965e-04 - mean_absolute_error: 0.0095 - val_loss: 5.7367e-05 - val_mean_absolute_error: 0.0057\n",
            "Epoch 157/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.2195e-04 - mean_absolute_error: 0.0093\n",
            "Epoch 00157: val_loss improved from 0.00004 to 0.00003, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 1.2195e-04 - mean_absolute_error: 0.0093 - val_loss: 3.3557e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 158/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.1307e-04 - mean_absolute_error: 0.0089\n",
            "Epoch 00158: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.1307e-04 - mean_absolute_error: 0.0089 - val_loss: 5.5001e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 159/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.9295e-05 - mean_absolute_error: 0.0086\n",
            "Epoch 00159: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 9.9295e-05 - mean_absolute_error: 0.0086 - val_loss: 6.9820e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 160/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.2248e-04 - mean_absolute_error: 0.0088\n",
            "Epoch 00160: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.2248e-04 - mean_absolute_error: 0.0088 - val_loss: 3.8707e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 161/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.0473e-04 - mean_absolute_error: 0.0086\n",
            "Epoch 00161: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 108ms/step - loss: 1.0473e-04 - mean_absolute_error: 0.0086 - val_loss: 4.8553e-05 - val_mean_absolute_error: 0.0061\n",
            "Epoch 162/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.1187e-04 - mean_absolute_error: 0.0088\n",
            "Epoch 00162: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 109ms/step - loss: 1.1187e-04 - mean_absolute_error: 0.0088 - val_loss: 4.6190e-05 - val_mean_absolute_error: 0.0066\n",
            "Epoch 163/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.6944e-04 - mean_absolute_error: 0.0097\n",
            "Epoch 00163: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.6944e-04 - mean_absolute_error: 0.0097 - val_loss: 8.9349e-05 - val_mean_absolute_error: 0.0075\n",
            "Epoch 164/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.2219e-04 - mean_absolute_error: 0.0092\n",
            "Epoch 00164: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 1.2219e-04 - mean_absolute_error: 0.0092 - val_loss: 6.4333e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 165/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.1731e-04 - mean_absolute_error: 0.0090\n",
            "Epoch 00165: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.1731e-04 - mean_absolute_error: 0.0090 - val_loss: 4.3079e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 166/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.1087e-04 - mean_absolute_error: 0.0086\n",
            "Epoch 00166: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.1087e-04 - mean_absolute_error: 0.0086 - val_loss: 4.4169e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 167/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.1721e-04 - mean_absolute_error: 0.0089\n",
            "Epoch 00167: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 1.1721e-04 - mean_absolute_error: 0.0089 - val_loss: 5.5059e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 168/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.1249e-04 - mean_absolute_error: 0.0089\n",
            "Epoch 00168: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.1249e-04 - mean_absolute_error: 0.0089 - val_loss: 4.8145e-05 - val_mean_absolute_error: 0.0066\n",
            "Epoch 169/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.1197e-04 - mean_absolute_error: 0.0090\n",
            "Epoch 00169: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 1.1197e-04 - mean_absolute_error: 0.0090 - val_loss: 7.1336e-05 - val_mean_absolute_error: 0.0065\n",
            "Epoch 170/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.3234e-04 - mean_absolute_error: 0.0091\n",
            "Epoch 00170: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 1.3234e-04 - mean_absolute_error: 0.0091 - val_loss: 9.7177e-05 - val_mean_absolute_error: 0.0077\n",
            "Epoch 171/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.1556e-04 - mean_absolute_error: 0.0090\n",
            "Epoch 00171: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 108ms/step - loss: 1.1556e-04 - mean_absolute_error: 0.0090 - val_loss: 3.8884e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 172/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.4892e-05 - mean_absolute_error: 0.0083\n",
            "Epoch 00172: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 9.4892e-05 - mean_absolute_error: 0.0083 - val_loss: 5.4307e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 173/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.1192e-04 - mean_absolute_error: 0.0089\n",
            "Epoch 00173: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 14s 110ms/step - loss: 1.1192e-04 - mean_absolute_error: 0.0089 - val_loss: 4.9372e-05 - val_mean_absolute_error: 0.0058\n",
            "Epoch 174/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.9808e-05 - mean_absolute_error: 0.0084\n",
            "Epoch 00174: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 9.9808e-05 - mean_absolute_error: 0.0084 - val_loss: 4.2872e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 175/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.2107e-04 - mean_absolute_error: 0.0089\n",
            "Epoch 00175: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 1.2107e-04 - mean_absolute_error: 0.0089 - val_loss: 1.0989e-04 - val_mean_absolute_error: 0.0069\n",
            "Epoch 176/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.2204e-04 - mean_absolute_error: 0.0090\n",
            "Epoch 00176: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 1.2204e-04 - mean_absolute_error: 0.0090 - val_loss: 6.6969e-05 - val_mean_absolute_error: 0.0070\n",
            "Epoch 177/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.0890e-04 - mean_absolute_error: 0.0087\n",
            "Epoch 00177: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 1.0890e-04 - mean_absolute_error: 0.0087 - val_loss: 4.6643e-05 - val_mean_absolute_error: 0.0054\n",
            "Epoch 178/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.0942e-04 - mean_absolute_error: 0.0089\n",
            "Epoch 00178: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 1.0942e-04 - mean_absolute_error: 0.0089 - val_loss: 6.4433e-05 - val_mean_absolute_error: 0.0067\n",
            "Epoch 179/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.2201e-04 - mean_absolute_error: 0.0088\n",
            "Epoch 00179: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 1.2201e-04 - mean_absolute_error: 0.0088 - val_loss: 5.2655e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 180/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.0693e-04 - mean_absolute_error: 0.0085\n",
            "Epoch 00180: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.0693e-04 - mean_absolute_error: 0.0085 - val_loss: 5.2747e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 181/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.1292e-04 - mean_absolute_error: 0.0085\n",
            "Epoch 00181: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.1292e-04 - mean_absolute_error: 0.0085 - val_loss: 1.1273e-04 - val_mean_absolute_error: 0.0060\n",
            "Epoch 182/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.5274e-04 - mean_absolute_error: 0.0094\n",
            "Epoch 00182: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 1.5274e-04 - mean_absolute_error: 0.0094 - val_loss: 4.5704e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 183/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.1698e-04 - mean_absolute_error: 0.0087\n",
            "Epoch 00183: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.1698e-04 - mean_absolute_error: 0.0087 - val_loss: 4.4911e-05 - val_mean_absolute_error: 0.0054\n",
            "Epoch 184/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.0025e-04 - mean_absolute_error: 0.0086\n",
            "Epoch 00184: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.0025e-04 - mean_absolute_error: 0.0086 - val_loss: 4.5531e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 185/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.0029e-04 - mean_absolute_error: 0.0085\n",
            "Epoch 00185: val_loss improved from 0.00003 to 0.00003, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 1.0029e-04 - mean_absolute_error: 0.0085 - val_loss: 3.1440e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 186/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.6036e-05 - mean_absolute_error: 0.0083\n",
            "Epoch 00186: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 9.6036e-05 - mean_absolute_error: 0.0083 - val_loss: 3.8022e-05 - val_mean_absolute_error: 0.0064\n",
            "Epoch 187/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.1978e-05 - mean_absolute_error: 0.0083\n",
            "Epoch 00187: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 9.1978e-05 - mean_absolute_error: 0.0083 - val_loss: 4.8017e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 188/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.0734e-04 - mean_absolute_error: 0.0085\n",
            "Epoch 00188: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.0734e-04 - mean_absolute_error: 0.0085 - val_loss: 5.4142e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 189/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.0629e-04 - mean_absolute_error: 0.0085\n",
            "Epoch 00189: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 1.0629e-04 - mean_absolute_error: 0.0085 - val_loss: 3.5326e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 190/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.0571e-04 - mean_absolute_error: 0.0084\n",
            "Epoch 00190: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 1.0571e-04 - mean_absolute_error: 0.0084 - val_loss: 4.3649e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 191/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.7365e-05 - mean_absolute_error: 0.0084\n",
            "Epoch 00191: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 9.7365e-05 - mean_absolute_error: 0.0084 - val_loss: 3.6739e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 192/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.0243e-04 - mean_absolute_error: 0.0083\n",
            "Epoch 00192: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 1.0243e-04 - mean_absolute_error: 0.0083 - val_loss: 4.2316e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 193/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.2228e-04 - mean_absolute_error: 0.0088\n",
            "Epoch 00193: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 1.2228e-04 - mean_absolute_error: 0.0088 - val_loss: 9.4031e-05 - val_mean_absolute_error: 0.0081\n",
            "Epoch 194/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.2557e-04 - mean_absolute_error: 0.0106\n",
            "Epoch 00194: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 2.2557e-04 - mean_absolute_error: 0.0106 - val_loss: 3.2169e-04 - val_mean_absolute_error: 0.0089\n",
            "Epoch 195/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 3.1928e-04 - mean_absolute_error: 0.0118\n",
            "Epoch 00195: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 3.1928e-04 - mean_absolute_error: 0.0118 - val_loss: 2.1018e-04 - val_mean_absolute_error: 0.0078\n",
            "Epoch 196/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.5297e-04 - mean_absolute_error: 0.0113\n",
            "Epoch 00196: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 2.5297e-04 - mean_absolute_error: 0.0113 - val_loss: 1.3426e-04 - val_mean_absolute_error: 0.0076\n",
            "Epoch 197/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.2106e-04 - mean_absolute_error: 0.0108\n",
            "Epoch 00197: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 14s 110ms/step - loss: 2.2106e-04 - mean_absolute_error: 0.0108 - val_loss: 1.1160e-04 - val_mean_absolute_error: 0.0061\n",
            "Epoch 198/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.5758e-04 - mean_absolute_error: 0.0112\n",
            "Epoch 00198: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 2.5758e-04 - mean_absolute_error: 0.0112 - val_loss: 2.1703e-04 - val_mean_absolute_error: 0.0076\n",
            "Epoch 199/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.3751e-04 - mean_absolute_error: 0.0113\n",
            "Epoch 00199: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 2.3751e-04 - mean_absolute_error: 0.0113 - val_loss: 1.0440e-04 - val_mean_absolute_error: 0.0060\n",
            "Epoch 200/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.4936e-04 - mean_absolute_error: 0.0110\n",
            "Epoch 00200: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 2.4936e-04 - mean_absolute_error: 0.0110 - val_loss: 3.0971e-04 - val_mean_absolute_error: 0.0110\n",
            "Epoch 201/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.2557e-04 - mean_absolute_error: 0.0107\n",
            "Epoch 00201: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 2.2557e-04 - mean_absolute_error: 0.0107 - val_loss: 9.0498e-05 - val_mean_absolute_error: 0.0058\n",
            "Epoch 202/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.7932e-04 - mean_absolute_error: 0.0113\n",
            "Epoch 00202: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 2.7932e-04 - mean_absolute_error: 0.0113 - val_loss: 2.2153e-04 - val_mean_absolute_error: 0.0076\n",
            "Epoch 203/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.8097e-04 - mean_absolute_error: 0.0114\n",
            "Epoch 00203: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 2.8097e-04 - mean_absolute_error: 0.0114 - val_loss: 1.6534e-04 - val_mean_absolute_error: 0.0069\n",
            "Epoch 204/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.8326e-04 - mean_absolute_error: 0.0099\n",
            "Epoch 00204: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.8326e-04 - mean_absolute_error: 0.0099 - val_loss: 7.9910e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 205/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.6743e-04 - mean_absolute_error: 0.0096\n",
            "Epoch 00205: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.6743e-04 - mean_absolute_error: 0.0096 - val_loss: 6.8397e-05 - val_mean_absolute_error: 0.0054\n",
            "Epoch 206/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.1988e-04 - mean_absolute_error: 0.0089\n",
            "Epoch 00206: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.1988e-04 - mean_absolute_error: 0.0089 - val_loss: 5.0632e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 207/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.4675e-04 - mean_absolute_error: 0.0092\n",
            "Epoch 00207: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 1.4675e-04 - mean_absolute_error: 0.0092 - val_loss: 4.3943e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 208/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.1394e-04 - mean_absolute_error: 0.0088\n",
            "Epoch 00208: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.1394e-04 - mean_absolute_error: 0.0088 - val_loss: 4.2142e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 209/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.0278e-04 - mean_absolute_error: 0.0086\n",
            "Epoch 00209: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 14s 110ms/step - loss: 1.0278e-04 - mean_absolute_error: 0.0086 - val_loss: 4.8429e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 210/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.5432e-04 - mean_absolute_error: 0.0093\n",
            "Epoch 00210: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 1.5432e-04 - mean_absolute_error: 0.0093 - val_loss: 4.8405e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 211/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.9189e-05 - mean_absolute_error: 0.0084\n",
            "Epoch 00211: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 9.9189e-05 - mean_absolute_error: 0.0084 - val_loss: 4.8101e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 212/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.5084e-05 - mean_absolute_error: 0.0083\n",
            "Epoch 00212: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 9.5084e-05 - mean_absolute_error: 0.0083 - val_loss: 3.8286e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 213/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.0482e-04 - mean_absolute_error: 0.0087\n",
            "Epoch 00213: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.0482e-04 - mean_absolute_error: 0.0087 - val_loss: 4.6185e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 214/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.2214e-05 - mean_absolute_error: 0.0082\n",
            "Epoch 00214: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 9.2214e-05 - mean_absolute_error: 0.0082 - val_loss: 3.8038e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 215/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.0194e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 00215: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 9.0194e-05 - mean_absolute_error: 0.0081 - val_loss: 4.2531e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 216/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.0303e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 00216: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 9.0303e-05 - mean_absolute_error: 0.0081 - val_loss: 3.9102e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 217/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.1438e-04 - mean_absolute_error: 0.0086\n",
            "Epoch 00217: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.1438e-04 - mean_absolute_error: 0.0086 - val_loss: 6.4476e-05 - val_mean_absolute_error: 0.0071\n",
            "Epoch 218/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.2023e-04 - mean_absolute_error: 0.0087\n",
            "Epoch 00218: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 1.2023e-04 - mean_absolute_error: 0.0087 - val_loss: 5.0868e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 219/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.0948e-04 - mean_absolute_error: 0.0086\n",
            "Epoch 00219: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.0948e-04 - mean_absolute_error: 0.0086 - val_loss: 4.1877e-05 - val_mean_absolute_error: 0.0054\n",
            "Epoch 220/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.0003e-04 - mean_absolute_error: 0.0084\n",
            "Epoch 00220: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 1.0003e-04 - mean_absolute_error: 0.0084 - val_loss: 5.1462e-05 - val_mean_absolute_error: 0.0076\n",
            "Epoch 221/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.0278e-04 - mean_absolute_error: 0.0083\n",
            "Epoch 00221: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 108ms/step - loss: 1.0278e-04 - mean_absolute_error: 0.0083 - val_loss: 4.5285e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 222/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.7980e-05 - mean_absolute_error: 0.0084\n",
            "Epoch 00222: val_loss improved from 0.00003 to 0.00003, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 9.7980e-05 - mean_absolute_error: 0.0084 - val_loss: 3.1016e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 223/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.0489e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 00223: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 9.0489e-05 - mean_absolute_error: 0.0080 - val_loss: 3.3866e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 224/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.6389e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 00224: val_loss improved from 0.00003 to 0.00003, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 8.6389e-05 - mean_absolute_error: 0.0079 - val_loss: 3.0759e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 225/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.7645e-05 - mean_absolute_error: 0.0082\n",
            "Epoch 00225: val_loss improved from 0.00003 to 0.00003, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 8.7645e-05 - mean_absolute_error: 0.0082 - val_loss: 2.8706e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 226/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.7233e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 00226: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 9.7233e-05 - mean_absolute_error: 0.0079 - val_loss: 4.1487e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 227/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.7193e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 00227: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 8.7193e-05 - mean_absolute_error: 0.0080 - val_loss: 3.9748e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 228/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.3231e-05 - mean_absolute_error: 0.0083\n",
            "Epoch 00228: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 9.3231e-05 - mean_absolute_error: 0.0083 - val_loss: 4.8678e-05 - val_mean_absolute_error: 0.0060\n",
            "Epoch 229/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.3157e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 00229: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 9.3157e-05 - mean_absolute_error: 0.0081 - val_loss: 4.4679e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 230/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.8643e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 00230: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 8.8643e-05 - mean_absolute_error: 0.0079 - val_loss: 5.5963e-05 - val_mean_absolute_error: 0.0064\n",
            "Epoch 231/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.8662e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 00231: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 8.8662e-05 - mean_absolute_error: 0.0080 - val_loss: 3.1973e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 232/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.4917e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 00232: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 108ms/step - loss: 9.4917e-05 - mean_absolute_error: 0.0081 - val_loss: 5.1887e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 233/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.9130e-05 - mean_absolute_error: 0.0082\n",
            "Epoch 00233: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 9.9130e-05 - mean_absolute_error: 0.0082 - val_loss: 7.8019e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 234/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.5136e-04 - mean_absolute_error: 0.0091\n",
            "Epoch 00234: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.5136e-04 - mean_absolute_error: 0.0091 - val_loss: 9.9369e-05 - val_mean_absolute_error: 0.0077\n",
            "Epoch 235/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.2672e-04 - mean_absolute_error: 0.0087\n",
            "Epoch 00235: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 1.2672e-04 - mean_absolute_error: 0.0087 - val_loss: 3.0778e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 236/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.9645e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 00236: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 8.9645e-05 - mean_absolute_error: 0.0079 - val_loss: 3.4226e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 237/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.0954e-04 - mean_absolute_error: 0.0083\n",
            "Epoch 00237: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 1.0954e-04 - mean_absolute_error: 0.0083 - val_loss: 3.9243e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 238/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.4833e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 00238: val_loss improved from 0.00003 to 0.00003, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 9.4833e-05 - mean_absolute_error: 0.0080 - val_loss: 2.8319e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 239/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.4955e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 00239: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 8.4955e-05 - mean_absolute_error: 0.0079 - val_loss: 3.2830e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 240/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.7075e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 00240: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 8.7075e-05 - mean_absolute_error: 0.0079 - val_loss: 6.2580e-05 - val_mean_absolute_error: 0.0060\n",
            "Epoch 241/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.4141e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 00241: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 9.4141e-05 - mean_absolute_error: 0.0080 - val_loss: 3.1130e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 242/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.0798e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 00242: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 8.0798e-05 - mean_absolute_error: 0.0079 - val_loss: 3.2142e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 243/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.6884e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 00243: val_loss improved from 0.00003 to 0.00003, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 8.6884e-05 - mean_absolute_error: 0.0079 - val_loss: 2.7923e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 244/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.4032e-05 - mean_absolute_error: 0.0078\n",
            "Epoch 00244: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 108ms/step - loss: 8.4032e-05 - mean_absolute_error: 0.0078 - val_loss: 2.9504e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 245/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.5836e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 00245: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 8.5836e-05 - mean_absolute_error: 0.0079 - val_loss: 3.3375e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 246/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.9910e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 00246: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 8.9910e-05 - mean_absolute_error: 0.0079 - val_loss: 2.9918e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 247/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.0465e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 00247: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 9.0465e-05 - mean_absolute_error: 0.0079 - val_loss: 5.3789e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 248/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.9499e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 00248: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 8.9499e-05 - mean_absolute_error: 0.0080 - val_loss: 3.1935e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 249/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.1784e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00249: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 8.1784e-05 - mean_absolute_error: 0.0077 - val_loss: 3.4934e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 250/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.9388e-05 - mean_absolute_error: 0.0078\n",
            "Epoch 00250: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 8.9388e-05 - mean_absolute_error: 0.0078 - val_loss: 3.2297e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 251/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.1295e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00251: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 8.1295e-05 - mean_absolute_error: 0.0077 - val_loss: 3.2627e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 252/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.0395e-04 - mean_absolute_error: 0.0081\n",
            "Epoch 00252: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 1.0395e-04 - mean_absolute_error: 0.0081 - val_loss: 4.1639e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 253/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.7839e-04 - mean_absolute_error: 0.0094\n",
            "Epoch 00253: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 1.7839e-04 - mean_absolute_error: 0.0094 - val_loss: 1.0345e-04 - val_mean_absolute_error: 0.0063\n",
            "Epoch 254/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.1420e-04 - mean_absolute_error: 0.0086\n",
            "Epoch 00254: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 1.1420e-04 - mean_absolute_error: 0.0086 - val_loss: 3.9998e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 255/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.4225e-04 - mean_absolute_error: 0.0090\n",
            "Epoch 00255: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 1.4225e-04 - mean_absolute_error: 0.0090 - val_loss: 2.3551e-04 - val_mean_absolute_error: 0.0096\n",
            "Epoch 256/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.3168e-04 - mean_absolute_error: 0.0089\n",
            "Epoch 00256: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 1.3168e-04 - mean_absolute_error: 0.0089 - val_loss: 5.6788e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 257/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.4468e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 00257: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 9.4468e-05 - mean_absolute_error: 0.0081 - val_loss: 5.7880e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 258/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.0205e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 00258: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 9.0205e-05 - mean_absolute_error: 0.0081 - val_loss: 6.1733e-05 - val_mean_absolute_error: 0.0060\n",
            "Epoch 259/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.5367e-05 - mean_absolute_error: 0.0078\n",
            "Epoch 00259: val_loss did not improve from 0.00003\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 8.5367e-05 - mean_absolute_error: 0.0078 - val_loss: 4.1224e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 260/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.7930e-05 - mean_absolute_error: 0.0078\n",
            "Epoch 00260: val_loss improved from 0.00003 to 0.00002, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 8.7930e-05 - mean_absolute_error: 0.0078 - val_loss: 2.4266e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 261/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.9846e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 00261: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 8.9846e-05 - mean_absolute_error: 0.0080 - val_loss: 2.9117e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 262/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.5597e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00262: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 8.5597e-05 - mean_absolute_error: 0.0077 - val_loss: 3.4116e-05 - val_mean_absolute_error: 0.0061\n",
            "Epoch 263/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.3644e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00263: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 8.3644e-05 - mean_absolute_error: 0.0077 - val_loss: 4.5594e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 264/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.7688e-05 - mean_absolute_error: 0.0078\n",
            "Epoch 00264: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 8.7688e-05 - mean_absolute_error: 0.0078 - val_loss: 2.9450e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 265/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.3486e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00265: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 8.3486e-05 - mean_absolute_error: 0.0076 - val_loss: 4.0169e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 266/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.1222e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 00266: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 9.1222e-05 - mean_absolute_error: 0.0080 - val_loss: 2.8360e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 267/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.3966e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00267: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 7.3966e-05 - mean_absolute_error: 0.0075 - val_loss: 2.4711e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 268/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.2146e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00268: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 108ms/step - loss: 8.2146e-05 - mean_absolute_error: 0.0076 - val_loss: 4.6332e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 269/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.7582e-05 - mean_absolute_error: 0.0078\n",
            "Epoch 00269: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 8.7582e-05 - mean_absolute_error: 0.0078 - val_loss: 6.4082e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 270/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.8557e-05 - mean_absolute_error: 0.0078\n",
            "Epoch 00270: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 8.8557e-05 - mean_absolute_error: 0.0078 - val_loss: 3.9661e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 271/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.6082e-05 - mean_absolute_error: 0.0078\n",
            "Epoch 00271: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 8.6082e-05 - mean_absolute_error: 0.0078 - val_loss: 2.8081e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 272/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.0426e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00272: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 8.0426e-05 - mean_absolute_error: 0.0076 - val_loss: 3.0619e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 273/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.1175e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 00273: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 9.1175e-05 - mean_absolute_error: 0.0079 - val_loss: 3.7536e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 274/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.6109e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 00274: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 8.6109e-05 - mean_absolute_error: 0.0079 - val_loss: 3.5357e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 275/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.5262e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 00275: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 9.5262e-05 - mean_absolute_error: 0.0079 - val_loss: 4.5919e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 276/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.2293e-05 - mean_absolute_error: 0.0078\n",
            "Epoch 00276: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 9.2293e-05 - mean_absolute_error: 0.0078 - val_loss: 3.7327e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 277/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.1053e-05 - mean_absolute_error: 0.0078\n",
            "Epoch 00277: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 9.1053e-05 - mean_absolute_error: 0.0078 - val_loss: 6.7440e-05 - val_mean_absolute_error: 0.0060\n",
            "Epoch 278/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.6650e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 00278: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 9.6650e-05 - mean_absolute_error: 0.0080 - val_loss: 3.0665e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 279/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.9699e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00279: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 7.9699e-05 - mean_absolute_error: 0.0076 - val_loss: 3.3159e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 280/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.1208e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00280: val_loss improved from 0.00002 to 0.00002, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 8.1208e-05 - mean_absolute_error: 0.0076 - val_loss: 2.1939e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 281/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.3450e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00281: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 8.3450e-05 - mean_absolute_error: 0.0076 - val_loss: 3.0749e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 282/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.4365e-05 - mean_absolute_error: 0.0078\n",
            "Epoch 00282: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 8.4365e-05 - mean_absolute_error: 0.0078 - val_loss: 3.1929e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 283/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.0304e-04 - mean_absolute_error: 0.0082\n",
            "Epoch 00283: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 1.0304e-04 - mean_absolute_error: 0.0082 - val_loss: 6.8516e-05 - val_mean_absolute_error: 0.0068\n",
            "Epoch 284/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.2391e-04 - mean_absolute_error: 0.0086\n",
            "Epoch 00284: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 1.2391e-04 - mean_absolute_error: 0.0086 - val_loss: 7.5392e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 285/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.9200e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 00285: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 9.9200e-05 - mean_absolute_error: 0.0081 - val_loss: 3.6141e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 286/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.5230e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00286: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 7.5230e-05 - mean_absolute_error: 0.0074 - val_loss: 2.3789e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 287/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.2770e-05 - mean_absolute_error: 0.0078\n",
            "Epoch 00287: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 9.2770e-05 - mean_absolute_error: 0.0078 - val_loss: 2.7809e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 288/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.9267e-05 - mean_absolute_error: 0.0081\n",
            "Epoch 00288: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 9.9267e-05 - mean_absolute_error: 0.0081 - val_loss: 3.6986e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 289/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.3971e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00289: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 8.3971e-05 - mean_absolute_error: 0.0077 - val_loss: 3.4909e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 290/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.3963e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00290: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 8.3963e-05 - mean_absolute_error: 0.0076 - val_loss: 4.2067e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 291/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.3784e-05 - mean_absolute_error: 0.0073\n",
            "Epoch 00291: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 7.3784e-05 - mean_absolute_error: 0.0073 - val_loss: 3.7345e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 292/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.3574e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00292: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 8.3574e-05 - mean_absolute_error: 0.0076 - val_loss: 4.3645e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 293/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.8872e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 00293: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 8.8872e-05 - mean_absolute_error: 0.0079 - val_loss: 2.3087e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 294/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.4831e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00294: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 7.4831e-05 - mean_absolute_error: 0.0074 - val_loss: 3.5385e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 295/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.6741e-04 - mean_absolute_error: 0.0091\n",
            "Epoch 00295: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 108ms/step - loss: 1.6741e-04 - mean_absolute_error: 0.0091 - val_loss: 6.8325e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 296/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.5049e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 00296: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 9.5049e-05 - mean_absolute_error: 0.0080 - val_loss: 3.3220e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 297/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.3756e-04 - mean_absolute_error: 0.0083\n",
            "Epoch 00297: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 1.3756e-04 - mean_absolute_error: 0.0083 - val_loss: 1.3195e-04 - val_mean_absolute_error: 0.0071\n",
            "Epoch 298/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.3254e-04 - mean_absolute_error: 0.0084\n",
            "Epoch 00298: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 1.3254e-04 - mean_absolute_error: 0.0084 - val_loss: 2.9435e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 299/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.8989e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00299: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 7.8989e-05 - mean_absolute_error: 0.0075 - val_loss: 2.5375e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 300/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.7994e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00300: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 7.7994e-05 - mean_absolute_error: 0.0076 - val_loss: 4.1209e-05 - val_mean_absolute_error: 0.0060\n",
            "Epoch 301/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.7400e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00301: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 7.7400e-05 - mean_absolute_error: 0.0075 - val_loss: 2.3086e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 302/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.5110e-04 - mean_absolute_error: 0.0088\n",
            "Epoch 00302: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 1.5110e-04 - mean_absolute_error: 0.0088 - val_loss: 3.8959e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 303/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.3070e-04 - mean_absolute_error: 0.0085\n",
            "Epoch 00303: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.3070e-04 - mean_absolute_error: 0.0085 - val_loss: 2.9004e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 304/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.9596e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00304: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 7.9596e-05 - mean_absolute_error: 0.0075 - val_loss: 4.4559e-05 - val_mean_absolute_error: 0.0053\n",
            "Epoch 305/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.8478e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00305: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 7.8478e-05 - mean_absolute_error: 0.0075 - val_loss: 2.9431e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 306/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.0915e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00306: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 8.0915e-05 - mean_absolute_error: 0.0076 - val_loss: 2.6361e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 307/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.9392e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00307: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 7.9392e-05 - mean_absolute_error: 0.0075 - val_loss: 3.0028e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 308/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.5625e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00308: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 7.5625e-05 - mean_absolute_error: 0.0074 - val_loss: 4.0944e-05 - val_mean_absolute_error: 0.0057\n",
            "Epoch 309/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.7243e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00309: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 7.7243e-05 - mean_absolute_error: 0.0075 - val_loss: 2.6974e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 310/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.0717e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00310: val_loss improved from 0.00002 to 0.00002, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 8.0717e-05 - mean_absolute_error: 0.0077 - val_loss: 2.1680e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 311/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.3502e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00311: val_loss improved from 0.00002 to 0.00002, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 7.3502e-05 - mean_absolute_error: 0.0072 - val_loss: 2.0947e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 312/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.2217e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00312: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 7.2217e-05 - mean_absolute_error: 0.0072 - val_loss: 3.7125e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 313/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.8825e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00313: val_loss improved from 0.00002 to 0.00002, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 6.8825e-05 - mean_absolute_error: 0.0071 - val_loss: 2.0728e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 314/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.8606e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00314: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 7.8606e-05 - mean_absolute_error: 0.0074 - val_loss: 3.0130e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 315/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.4187e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00315: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 8.4187e-05 - mean_absolute_error: 0.0076 - val_loss: 3.0436e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 316/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.4273e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 00316: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 9.4273e-05 - mean_absolute_error: 0.0080 - val_loss: 4.6554e-05 - val_mean_absolute_error: 0.0065\n",
            "Epoch 317/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.7706e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00317: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 7.7706e-05 - mean_absolute_error: 0.0076 - val_loss: 2.5402e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 318/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.9553e-05 - mean_absolute_error: 0.0073\n",
            "Epoch 00318: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 7.9553e-05 - mean_absolute_error: 0.0073 - val_loss: 2.9688e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 319/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.1274e-04 - mean_absolute_error: 0.0081\n",
            "Epoch 00319: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 1.1274e-04 - mean_absolute_error: 0.0081 - val_loss: 3.6600e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 320/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.7514e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00320: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 8.7514e-05 - mean_absolute_error: 0.0076 - val_loss: 3.0548e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 321/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.9833e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00321: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 7.9833e-05 - mean_absolute_error: 0.0075 - val_loss: 2.9856e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 322/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.8131e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00322: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 7.8131e-05 - mean_absolute_error: 0.0074 - val_loss: 2.6454e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 323/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.6282e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00323: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 7.6282e-05 - mean_absolute_error: 0.0075 - val_loss: 3.7391e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 324/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.8082e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00324: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 8.8082e-05 - mean_absolute_error: 0.0075 - val_loss: 3.0449e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 325/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.8596e-05 - mean_absolute_error: 0.0073\n",
            "Epoch 00325: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 7.8596e-05 - mean_absolute_error: 0.0073 - val_loss: 2.8520e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 326/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.0635e-04 - mean_absolute_error: 0.0079\n",
            "Epoch 00326: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 108ms/step - loss: 1.0635e-04 - mean_absolute_error: 0.0079 - val_loss: 2.0903e-04 - val_mean_absolute_error: 0.0073\n",
            "Epoch 327/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.2960e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00327: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 9.2960e-05 - mean_absolute_error: 0.0077 - val_loss: 2.6598e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 328/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.4193e-05 - mean_absolute_error: 0.0079\n",
            "Epoch 00328: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 9.4193e-05 - mean_absolute_error: 0.0079 - val_loss: 7.0764e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 329/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.3664e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00329: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 8.3664e-05 - mean_absolute_error: 0.0076 - val_loss: 3.0776e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 330/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 2.1335e-04 - mean_absolute_error: 0.0096\n",
            "Epoch 00330: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 2.1335e-04 - mean_absolute_error: 0.0096 - val_loss: 9.5222e-05 - val_mean_absolute_error: 0.0054\n",
            "Epoch 331/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.5509e-05 - mean_absolute_error: 0.0080\n",
            "Epoch 00331: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 9.5509e-05 - mean_absolute_error: 0.0080 - val_loss: 3.4857e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 332/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.4655e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00332: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 109ms/step - loss: 8.4655e-05 - mean_absolute_error: 0.0075 - val_loss: 2.1582e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 333/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.3324e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00333: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 7.3324e-05 - mean_absolute_error: 0.0072 - val_loss: 2.0755e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 334/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.5284e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00334: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 7.5284e-05 - mean_absolute_error: 0.0074 - val_loss: 2.8133e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 335/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.3270e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00335: val_loss improved from 0.00002 to 0.00002, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 7.3270e-05 - mean_absolute_error: 0.0072 - val_loss: 2.0177e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 336/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.2119e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00336: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 7.2119e-05 - mean_absolute_error: 0.0071 - val_loss: 2.5732e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 337/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.4685e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00337: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 7.4685e-05 - mean_absolute_error: 0.0072 - val_loss: 2.8058e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 338/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.8549e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00338: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 7.8549e-05 - mean_absolute_error: 0.0074 - val_loss: 2.5015e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 339/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.4712e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00339: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 8.4712e-05 - mean_absolute_error: 0.0075 - val_loss: 3.0154e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 340/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.6753e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00340: val_loss improved from 0.00002 to 0.00002, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 109ms/step - loss: 7.6753e-05 - mean_absolute_error: 0.0074 - val_loss: 1.9710e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 341/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.8203e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00341: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 109ms/step - loss: 7.8203e-05 - mean_absolute_error: 0.0075 - val_loss: 4.5201e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 342/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.3100e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00342: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 14s 110ms/step - loss: 7.3100e-05 - mean_absolute_error: 0.0072 - val_loss: 4.4736e-05 - val_mean_absolute_error: 0.0052\n",
            "Epoch 343/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.7850e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00343: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 8.7850e-05 - mean_absolute_error: 0.0076 - val_loss: 5.6116e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 344/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.6593e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00344: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 8.6593e-05 - mean_absolute_error: 0.0076 - val_loss: 4.8987e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 345/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.0331e-04 - mean_absolute_error: 0.0080\n",
            "Epoch 00345: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 1.0331e-04 - mean_absolute_error: 0.0080 - val_loss: 2.7020e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 346/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.1524e-05 - mean_absolute_error: 0.0073\n",
            "Epoch 00346: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 7.1524e-05 - mean_absolute_error: 0.0073 - val_loss: 3.0574e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 347/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.5624e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00347: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 8.5624e-05 - mean_absolute_error: 0.0077 - val_loss: 1.9747e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 348/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.1257e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00348: val_loss improved from 0.00002 to 0.00002, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 108ms/step - loss: 7.1257e-05 - mean_absolute_error: 0.0072 - val_loss: 1.9541e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 349/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.2915e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00349: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 110ms/step - loss: 8.2915e-05 - mean_absolute_error: 0.0074 - val_loss: 3.4256e-04 - val_mean_absolute_error: 0.0085\n",
            "Epoch 350/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.8732e-04 - mean_absolute_error: 0.0097\n",
            "Epoch 00350: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 1.8732e-04 - mean_absolute_error: 0.0097 - val_loss: 2.2102e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 351/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.7701e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00351: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 7.7701e-05 - mean_absolute_error: 0.0075 - val_loss: 2.6331e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 352/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.3738e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00352: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 9.3738e-05 - mean_absolute_error: 0.0077 - val_loss: 3.6147e-05 - val_mean_absolute_error: 0.0059\n",
            "Epoch 353/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.5797e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00353: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 8.5797e-05 - mean_absolute_error: 0.0076 - val_loss: 2.4481e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 354/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.0002e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00354: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 7.0002e-05 - mean_absolute_error: 0.0071 - val_loss: 2.7166e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 355/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.9509e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00355: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 7.9509e-05 - mean_absolute_error: 0.0074 - val_loss: 1.9706e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 356/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.3493e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00356: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 7.3493e-05 - mean_absolute_error: 0.0071 - val_loss: 2.7345e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 357/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.0945e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00357: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 7.0945e-05 - mean_absolute_error: 0.0071 - val_loss: 2.0888e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 358/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.3937e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00358: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 7.3937e-05 - mean_absolute_error: 0.0072 - val_loss: 2.6206e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 359/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.1069e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00359: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 7.1069e-05 - mean_absolute_error: 0.0072 - val_loss: 3.8093e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 360/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.8259e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00360: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 6.8259e-05 - mean_absolute_error: 0.0070 - val_loss: 5.5618e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 361/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.0194e-04 - mean_absolute_error: 0.0078\n",
            "Epoch 00361: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 1.0194e-04 - mean_absolute_error: 0.0078 - val_loss: 3.1220e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 362/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.5814e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00362: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 7.5814e-05 - mean_absolute_error: 0.0072 - val_loss: 2.7146e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 363/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.0509e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00363: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 8.0509e-05 - mean_absolute_error: 0.0075 - val_loss: 3.3281e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 364/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.7012e-04 - mean_absolute_error: 0.0092\n",
            "Epoch 00364: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 1.7012e-04 - mean_absolute_error: 0.0092 - val_loss: 8.2516e-05 - val_mean_absolute_error: 0.0056\n",
            "Epoch 365/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.0504e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00365: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 9.0504e-05 - mean_absolute_error: 0.0077 - val_loss: 2.0825e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 366/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.4523e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00366: val_loss improved from 0.00002 to 0.00002, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 7.4523e-05 - mean_absolute_error: 0.0074 - val_loss: 1.9374e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 367/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.4205e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00367: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 6.4205e-05 - mean_absolute_error: 0.0069 - val_loss: 2.3534e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 368/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.5185e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00368: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 7.5185e-05 - mean_absolute_error: 0.0071 - val_loss: 2.0909e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 369/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.4834e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00369: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 7.4834e-05 - mean_absolute_error: 0.0072 - val_loss: 2.7148e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 370/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.5203e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00370: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 7.5203e-05 - mean_absolute_error: 0.0072 - val_loss: 3.0810e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 371/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.7408e-05 - mean_absolute_error: 0.0073\n",
            "Epoch 00371: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 7.7408e-05 - mean_absolute_error: 0.0073 - val_loss: 4.0016e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 372/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.9353e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00372: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 6.9353e-05 - mean_absolute_error: 0.0072 - val_loss: 5.0243e-05 - val_mean_absolute_error: 0.0063\n",
            "Epoch 373/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.8898e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00373: val_loss improved from 0.00002 to 0.00002, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 6.8898e-05 - mean_absolute_error: 0.0070 - val_loss: 1.8035e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 374/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.7289e-05 - mean_absolute_error: 0.0073\n",
            "Epoch 00374: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 7.7289e-05 - mean_absolute_error: 0.0073 - val_loss: 3.6476e-05 - val_mean_absolute_error: 0.0048\n",
            "Epoch 375/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.4568e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00375: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 7.4568e-05 - mean_absolute_error: 0.0072 - val_loss: 2.8054e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 376/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.7174e-05 - mean_absolute_error: 0.0077\n",
            "Epoch 00376: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 8.7174e-05 - mean_absolute_error: 0.0077 - val_loss: 1.7826e-04 - val_mean_absolute_error: 0.0098\n",
            "Epoch 377/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.6573e-04 - mean_absolute_error: 0.0090\n",
            "Epoch 00377: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.6573e-04 - mean_absolute_error: 0.0090 - val_loss: 2.6393e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 378/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.2151e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00378: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 7.2151e-05 - mean_absolute_error: 0.0071 - val_loss: 2.2010e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 379/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.3466e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00379: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 7.3466e-05 - mean_absolute_error: 0.0070 - val_loss: 3.2937e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 380/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.3019e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00380: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 7.3019e-05 - mean_absolute_error: 0.0071 - val_loss: 2.6214e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 381/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.2009e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00381: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 7.2009e-05 - mean_absolute_error: 0.0071 - val_loss: 3.7432e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 382/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.9098e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00382: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 6.9098e-05 - mean_absolute_error: 0.0071 - val_loss: 2.3826e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 383/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.4766e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00383: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 6.4766e-05 - mean_absolute_error: 0.0069 - val_loss: 2.3472e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 384/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.5700e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00384: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 7.5700e-05 - mean_absolute_error: 0.0072 - val_loss: 2.8940e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 385/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.8678e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00385: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 6.8678e-05 - mean_absolute_error: 0.0069 - val_loss: 4.7154e-05 - val_mean_absolute_error: 0.0051\n",
            "Epoch 386/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.0040e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00386: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 7.0040e-05 - mean_absolute_error: 0.0071 - val_loss: 2.1176e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 387/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.2818e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00387: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 6.2818e-05 - mean_absolute_error: 0.0067 - val_loss: 2.0849e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 388/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.1940e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00388: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 109ms/step - loss: 7.1940e-05 - mean_absolute_error: 0.0069 - val_loss: 2.5816e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 389/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.3723e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00389: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 7.3723e-05 - mean_absolute_error: 0.0070 - val_loss: 1.9958e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 390/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.3622e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00390: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 6.3622e-05 - mean_absolute_error: 0.0068 - val_loss: 2.3048e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 391/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.1468e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00391: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 7.1468e-05 - mean_absolute_error: 0.0070 - val_loss: 5.8271e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 392/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.0383e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00392: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 8.0383e-05 - mean_absolute_error: 0.0072 - val_loss: 3.4277e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 393/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.1639e-04 - mean_absolute_error: 0.0080\n",
            "Epoch 00393: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 1.1639e-04 - mean_absolute_error: 0.0080 - val_loss: 1.4478e-04 - val_mean_absolute_error: 0.0074\n",
            "Epoch 394/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.7085e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00394: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 8.7085e-05 - mean_absolute_error: 0.0075 - val_loss: 2.4296e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 395/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.2218e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00395: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 7.2218e-05 - mean_absolute_error: 0.0071 - val_loss: 2.4085e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 396/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.0717e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00396: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 7.0717e-05 - mean_absolute_error: 0.0070 - val_loss: 1.9731e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 397/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.8840e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00397: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 6.8840e-05 - mean_absolute_error: 0.0069 - val_loss: 2.4586e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 398/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.3701e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00398: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 7.3701e-05 - mean_absolute_error: 0.0071 - val_loss: 2.8804e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 399/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.0711e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00399: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 7.0711e-05 - mean_absolute_error: 0.0071 - val_loss: 2.8206e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 400/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.3081e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00400: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 6.3081e-05 - mean_absolute_error: 0.0068 - val_loss: 2.1096e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 401/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.1940e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00401: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 7.1940e-05 - mean_absolute_error: 0.0071 - val_loss: 4.3163e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 402/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.9165e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00402: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 6.9165e-05 - mean_absolute_error: 0.0068 - val_loss: 1.9338e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 403/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.2965e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00403: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 7.2965e-05 - mean_absolute_error: 0.0070 - val_loss: 1.8639e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 404/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.6445e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00404: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 6.6445e-05 - mean_absolute_error: 0.0069 - val_loss: 2.3869e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 405/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.9129e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00405: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 6.9129e-05 - mean_absolute_error: 0.0069 - val_loss: 2.4887e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 406/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.7270e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00406: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 6.7270e-05 - mean_absolute_error: 0.0069 - val_loss: 2.3963e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 407/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.8775e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00407: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 6.8775e-05 - mean_absolute_error: 0.0070 - val_loss: 1.9609e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 408/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.3974e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00408: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 6.3974e-05 - mean_absolute_error: 0.0067 - val_loss: 2.1446e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 409/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.9223e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00409: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 6.9223e-05 - mean_absolute_error: 0.0069 - val_loss: 2.2823e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 410/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.9952e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00410: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 6.9952e-05 - mean_absolute_error: 0.0069 - val_loss: 2.1244e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 411/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.9460e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00411: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 6.9460e-05 - mean_absolute_error: 0.0070 - val_loss: 4.2091e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 412/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.5073e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00412: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 108ms/step - loss: 7.5073e-05 - mean_absolute_error: 0.0071 - val_loss: 2.7076e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 413/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.3170e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00413: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 7.3170e-05 - mean_absolute_error: 0.0070 - val_loss: 1.9609e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 414/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.7016e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00414: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 7.7016e-05 - mean_absolute_error: 0.0071 - val_loss: 4.4612e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 415/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.1725e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00415: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 7.1725e-05 - mean_absolute_error: 0.0071 - val_loss: 2.6669e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 416/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.3103e-04 - mean_absolute_error: 0.0085\n",
            "Epoch 00416: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 1.3103e-04 - mean_absolute_error: 0.0085 - val_loss: 8.5252e-05 - val_mean_absolute_error: 0.0070\n",
            "Epoch 417/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.7439e-05 - mean_absolute_error: 0.0074\n",
            "Epoch 00417: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 8.7439e-05 - mean_absolute_error: 0.0074 - val_loss: 2.2376e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 418/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.1496e-04 - mean_absolute_error: 0.0081\n",
            "Epoch 00418: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 1.1496e-04 - mean_absolute_error: 0.0081 - val_loss: 2.3788e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 419/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.0350e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00419: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 7.0350e-05 - mean_absolute_error: 0.0070 - val_loss: 2.2158e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 420/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.0821e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00420: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 7.0821e-05 - mean_absolute_error: 0.0071 - val_loss: 2.1959e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 421/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.8377e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00421: val_loss improved from 0.00002 to 0.00002, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 6.8377e-05 - mean_absolute_error: 0.0069 - val_loss: 1.7527e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 422/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.2828e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00422: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 7.2828e-05 - mean_absolute_error: 0.0069 - val_loss: 3.5418e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 423/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.3577e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00423: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 7.3577e-05 - mean_absolute_error: 0.0071 - val_loss: 2.2881e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 424/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.9716e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00424: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 6.9716e-05 - mean_absolute_error: 0.0069 - val_loss: 3.2625e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 425/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.4618e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00425: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 7.4618e-05 - mean_absolute_error: 0.0071 - val_loss: 2.5620e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 426/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.8113e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00426: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 6.8113e-05 - mean_absolute_error: 0.0069 - val_loss: 2.4307e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 427/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.3500e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00427: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 7.3500e-05 - mean_absolute_error: 0.0071 - val_loss: 3.5905e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 428/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.1482e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00428: val_loss improved from 0.00002 to 0.00002, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 7.1482e-05 - mean_absolute_error: 0.0070 - val_loss: 1.7002e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 429/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.4753e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00429: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 6.4753e-05 - mean_absolute_error: 0.0068 - val_loss: 1.9416e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 430/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.7837e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00430: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 6.7837e-05 - mean_absolute_error: 0.0068 - val_loss: 1.8933e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 431/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.1894e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00431: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 7.1894e-05 - mean_absolute_error: 0.0069 - val_loss: 2.0511e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 432/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.4205e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00432: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 6.4205e-05 - mean_absolute_error: 0.0069 - val_loss: 2.2296e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 433/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.5235e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00433: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 6.5235e-05 - mean_absolute_error: 0.0068 - val_loss: 2.5632e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 434/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.4498e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00434: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 6.4498e-05 - mean_absolute_error: 0.0069 - val_loss: 2.6838e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 435/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.3043e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00435: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 7.3043e-05 - mean_absolute_error: 0.0069 - val_loss: 3.5949e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 436/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.8621e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00436: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 7.8621e-05 - mean_absolute_error: 0.0072 - val_loss: 3.5857e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 437/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.6675e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00437: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 7.6675e-05 - mean_absolute_error: 0.0072 - val_loss: 3.0556e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 438/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.7920e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00438: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 6.7920e-05 - mean_absolute_error: 0.0071 - val_loss: 3.6982e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 439/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.6026e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00439: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 6.6026e-05 - mean_absolute_error: 0.0068 - val_loss: 1.9579e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 440/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.7615e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00440: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 6.7615e-05 - mean_absolute_error: 0.0068 - val_loss: 2.9716e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 441/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.4158e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00441: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 7.4158e-05 - mean_absolute_error: 0.0071 - val_loss: 5.2942e-05 - val_mean_absolute_error: 0.0055\n",
            "Epoch 442/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.7531e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00442: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 6.7531e-05 - mean_absolute_error: 0.0069 - val_loss: 3.1273e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 443/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.0377e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00443: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 6.0377e-05 - mean_absolute_error: 0.0068 - val_loss: 2.6789e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 444/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.7751e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00444: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 6.7751e-05 - mean_absolute_error: 0.0068 - val_loss: 2.5480e-05 - val_mean_absolute_error: 0.0040\n",
            "Epoch 445/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.0143e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00445: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 8.0143e-05 - mean_absolute_error: 0.0070 - val_loss: 2.5442e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 446/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.2472e-05 - mean_absolute_error: 0.0075\n",
            "Epoch 00446: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 9.2472e-05 - mean_absolute_error: 0.0075 - val_loss: 3.6058e-05 - val_mean_absolute_error: 0.0043\n",
            "Epoch 447/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.5954e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00447: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 7.5954e-05 - mean_absolute_error: 0.0072 - val_loss: 2.6507e-05 - val_mean_absolute_error: 0.0047\n",
            "Epoch 448/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.2204e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00448: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 7.2204e-05 - mean_absolute_error: 0.0071 - val_loss: 2.6230e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 449/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.5970e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00449: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 6.5970e-05 - mean_absolute_error: 0.0070 - val_loss: 2.0771e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 450/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.4810e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00450: val_loss improved from 0.00002 to 0.00002, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 6.4810e-05 - mean_absolute_error: 0.0068 - val_loss: 1.5013e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 451/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.6580e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00451: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 7.6580e-05 - mean_absolute_error: 0.0070 - val_loss: 4.3865e-05 - val_mean_absolute_error: 0.0046\n",
            "Epoch 452/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.7926e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00452: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 6.7926e-05 - mean_absolute_error: 0.0070 - val_loss: 2.4029e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 453/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.8112e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00453: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 6.8112e-05 - mean_absolute_error: 0.0069 - val_loss: 2.0231e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 454/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 9.6834e-05 - mean_absolute_error: 0.0072\n",
            "Epoch 00454: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 9.6834e-05 - mean_absolute_error: 0.0072 - val_loss: 1.1316e-04 - val_mean_absolute_error: 0.0060\n",
            "Epoch 455/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.0451e-04 - mean_absolute_error: 0.0075\n",
            "Epoch 00455: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 1.0451e-04 - mean_absolute_error: 0.0075 - val_loss: 6.2457e-05 - val_mean_absolute_error: 0.0050\n",
            "Epoch 456/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 1.0236e-04 - mean_absolute_error: 0.0079\n",
            "Epoch 00456: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 1.0236e-04 - mean_absolute_error: 0.0079 - val_loss: 3.7820e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 457/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.7619e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00457: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 104ms/step - loss: 7.7619e-05 - mean_absolute_error: 0.0071 - val_loss: 2.8260e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 458/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 5.7250e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00458: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 5.7250e-05 - mean_absolute_error: 0.0065 - val_loss: 2.1075e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 459/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.1745e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00459: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 7.1745e-05 - mean_absolute_error: 0.0069 - val_loss: 6.0469e-05 - val_mean_absolute_error: 0.0045\n",
            "Epoch 460/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.5062e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00460: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 109ms/step - loss: 6.5062e-05 - mean_absolute_error: 0.0068 - val_loss: 1.7055e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 461/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.3450e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00461: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 6.3450e-05 - mean_absolute_error: 0.0066 - val_loss: 2.7431e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 462/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 5.7584e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00462: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 5.7584e-05 - mean_absolute_error: 0.0065 - val_loss: 2.4831e-05 - val_mean_absolute_error: 0.0041\n",
            "Epoch 463/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.2098e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00463: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 6.2098e-05 - mean_absolute_error: 0.0066 - val_loss: 1.9764e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 464/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.4630e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00464: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 6.4630e-05 - mean_absolute_error: 0.0066 - val_loss: 3.4311e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 465/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.2966e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00465: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 6.2966e-05 - mean_absolute_error: 0.0066 - val_loss: 2.9209e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 466/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.4706e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00466: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 109ms/step - loss: 6.4706e-05 - mean_absolute_error: 0.0066 - val_loss: 2.3452e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 467/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.7360e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00467: val_loss did not improve from 0.00002\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 6.7360e-05 - mean_absolute_error: 0.0068 - val_loss: 1.8057e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 468/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.2405e-05 - mean_absolute_error: 0.0070\n",
            "Epoch 00468: val_loss improved from 0.00002 to 0.00001, saving model to results/2020-07-26_AAPL-huber_loss-adam-LSTM-seq-100-step-50-layers-3-units-256.h5\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 7.2405e-05 - mean_absolute_error: 0.0070 - val_loss: 1.4917e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 469/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.0762e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00469: val_loss did not improve from 0.00001\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 6.0762e-05 - mean_absolute_error: 0.0066 - val_loss: 2.3642e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 470/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.2093e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00470: val_loss did not improve from 0.00001\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 6.2093e-05 - mean_absolute_error: 0.0066 - val_loss: 2.6252e-05 - val_mean_absolute_error: 0.0034\n",
            "Epoch 471/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.5540e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00471: val_loss did not improve from 0.00001\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 6.5540e-05 - mean_absolute_error: 0.0067 - val_loss: 2.5953e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 472/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.2073e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00472: val_loss did not improve from 0.00001\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 6.2073e-05 - mean_absolute_error: 0.0065 - val_loss: 2.1050e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 473/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.6158e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00473: val_loss did not improve from 0.00001\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 6.6158e-05 - mean_absolute_error: 0.0066 - val_loss: 4.0547e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 474/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.0705e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00474: val_loss did not improve from 0.00001\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 7.0705e-05 - mean_absolute_error: 0.0069 - val_loss: 2.5598e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 475/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.4129e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00475: val_loss did not improve from 0.00001\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 7.4129e-05 - mean_absolute_error: 0.0071 - val_loss: 2.0771e-05 - val_mean_absolute_error: 0.0029\n",
            "Epoch 476/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.2225e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00476: val_loss did not improve from 0.00001\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 6.2225e-05 - mean_absolute_error: 0.0066 - val_loss: 1.8251e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 477/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.3421e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00477: val_loss did not improve from 0.00001\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 6.3421e-05 - mean_absolute_error: 0.0067 - val_loss: 1.5737e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 478/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.2300e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00478: val_loss did not improve from 0.00001\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 6.2300e-05 - mean_absolute_error: 0.0066 - val_loss: 3.3410e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 479/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.4223e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00479: val_loss did not improve from 0.00001\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 6.4223e-05 - mean_absolute_error: 0.0068 - val_loss: 1.5466e-05 - val_mean_absolute_error: 0.0027\n",
            "Epoch 480/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 5.8443e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00480: val_loss did not improve from 0.00001\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 5.8443e-05 - mean_absolute_error: 0.0065 - val_loss: 2.2508e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 481/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.9562e-05 - mean_absolute_error: 0.0076\n",
            "Epoch 00481: val_loss did not improve from 0.00001\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 8.9562e-05 - mean_absolute_error: 0.0076 - val_loss: 1.9228e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 482/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.7557e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00482: val_loss did not improve from 0.00001\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 6.7557e-05 - mean_absolute_error: 0.0068 - val_loss: 1.9862e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 483/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.2237e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00483: val_loss did not improve from 0.00001\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 6.2237e-05 - mean_absolute_error: 0.0065 - val_loss: 1.9009e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 484/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.3527e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00484: val_loss did not improve from 0.00001\n",
            "123/123 [==============================] - 13s 108ms/step - loss: 6.3527e-05 - mean_absolute_error: 0.0066 - val_loss: 2.1164e-05 - val_mean_absolute_error: 0.0030\n",
            "Epoch 485/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 8.0200e-05 - mean_absolute_error: 0.0071\n",
            "Epoch 00485: val_loss did not improve from 0.00001\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 8.0200e-05 - mean_absolute_error: 0.0071 - val_loss: 2.9244e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 486/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.9756e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00486: val_loss did not improve from 0.00001\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 6.9756e-05 - mean_absolute_error: 0.0068 - val_loss: 4.0517e-05 - val_mean_absolute_error: 0.0049\n",
            "Epoch 487/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.8904e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00487: val_loss did not improve from 0.00001\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 6.8904e-05 - mean_absolute_error: 0.0069 - val_loss: 1.7349e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 488/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.4053e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00488: val_loss did not improve from 0.00001\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 6.4053e-05 - mean_absolute_error: 0.0066 - val_loss: 1.6581e-05 - val_mean_absolute_error: 0.0038\n",
            "Epoch 489/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.0235e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00489: val_loss did not improve from 0.00001\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 7.0235e-05 - mean_absolute_error: 0.0067 - val_loss: 2.8089e-05 - val_mean_absolute_error: 0.0035\n",
            "Epoch 490/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.7443e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00490: val_loss did not improve from 0.00001\n",
            "123/123 [==============================] - 13s 107ms/step - loss: 6.7443e-05 - mean_absolute_error: 0.0067 - val_loss: 2.5672e-05 - val_mean_absolute_error: 0.0042\n",
            "Epoch 491/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.2349e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00491: val_loss did not improve from 0.00001\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 6.2349e-05 - mean_absolute_error: 0.0066 - val_loss: 3.4444e-05 - val_mean_absolute_error: 0.0044\n",
            "Epoch 492/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.1893e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00492: val_loss did not improve from 0.00001\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 6.1893e-05 - mean_absolute_error: 0.0066 - val_loss: 2.5404e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 493/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.1474e-05 - mean_absolute_error: 0.0065\n",
            "Epoch 00493: val_loss did not improve from 0.00001\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 6.1474e-05 - mean_absolute_error: 0.0065 - val_loss: 1.9126e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 494/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.1006e-05 - mean_absolute_error: 0.0064\n",
            "Epoch 00494: val_loss did not improve from 0.00001\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 6.1006e-05 - mean_absolute_error: 0.0064 - val_loss: 3.0550e-05 - val_mean_absolute_error: 0.0037\n",
            "Epoch 495/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 7.4204e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00495: val_loss did not improve from 0.00001\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 7.4204e-05 - mean_absolute_error: 0.0069 - val_loss: 2.0840e-05 - val_mean_absolute_error: 0.0033\n",
            "Epoch 496/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.7334e-05 - mean_absolute_error: 0.0067\n",
            "Epoch 00496: val_loss did not improve from 0.00001\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 6.7334e-05 - mean_absolute_error: 0.0067 - val_loss: 2.9298e-05 - val_mean_absolute_error: 0.0039\n",
            "Epoch 497/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.3210e-05 - mean_absolute_error: 0.0066\n",
            "Epoch 00497: val_loss did not improve from 0.00001\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 6.3210e-05 - mean_absolute_error: 0.0066 - val_loss: 2.1313e-05 - val_mean_absolute_error: 0.0031\n",
            "Epoch 498/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.8866e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00498: val_loss did not improve from 0.00001\n",
            "123/123 [==============================] - 13s 105ms/step - loss: 6.8866e-05 - mean_absolute_error: 0.0068 - val_loss: 2.1353e-05 - val_mean_absolute_error: 0.0036\n",
            "Epoch 499/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.6249e-05 - mean_absolute_error: 0.0068\n",
            "Epoch 00499: val_loss did not improve from 0.00001\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 6.6249e-05 - mean_absolute_error: 0.0068 - val_loss: 2.1934e-05 - val_mean_absolute_error: 0.0032\n",
            "Epoch 500/500\n",
            "123/123 [==============================] - ETA: 0s - loss: 6.7747e-05 - mean_absolute_error: 0.0069\n",
            "Epoch 00500: val_loss did not improve from 0.00001\n",
            "123/123 [==============================] - 13s 106ms/step - loss: 6.7747e-05 - mean_absolute_error: 0.0069 - val_loss: 2.2648e-05 - val_mean_absolute_error: 0.0036\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sM-XsfOvpVI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = load_data(ticker, N_STEPS, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE,\n",
        "                feature_columns=FEATURE_COLUMNS, shuffle=False)\n",
        "\n",
        "# construct the model\n",
        "#model = create_model(N_STEPS, loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
        "                    #dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
        "\n",
        "model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
        "model.load_weights(model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oa-bMqcHqF8Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9cb783f-5aea-4abc-bc7f-42a7ed80e4c5"
      },
      "source": [
        "# evaluate the model\n",
        "mse, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
        "# calculate the mean absolute error (inverse scaling)\n",
        "mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n",
        "print(\"Mean Absolute Error:\", mean_absolute_error)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 3.87607588716422\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYAB0IQrqQcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model, data, classification=False):\n",
        "    # retrieve the last sequence from data\n",
        "    last_sequence = data[\"last_sequence\"][:N_STEPS]\n",
        "    # retrieve the column scalers\n",
        "    column_scaler = data[\"column_scaler\"]\n",
        "    # reshape the last sequence\n",
        "    last_sequence = last_sequence.reshape((last_sequence.shape[1], last_sequence.shape[0]))\n",
        "    # expand dimension\n",
        "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
        "    # get the prediction (scaled from 0 to 1)\n",
        "    prediction = model.predict(last_sequence)\n",
        "    # get the price (by inverting the scaling)\n",
        "    predicted_price = column_scaler[\"adjclose\"].inverse_transform(prediction)[0][0]\n",
        "    return predicted_price"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Drew5yWUqYCW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3cfbbdc9-7505-4259-c0a0-50790abecdb0"
      },
      "source": [
        "# predict the future price\n",
        "future_price = predict(model, data)\n",
        "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Future price after 50 days is 385.97$\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KThh2jxJqjIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_graph(model, data):\n",
        "    y_test = data[\"y_test\"]\n",
        "    X_test = data[\"X_test\"]\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
        "    y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
        "    # last 200 days, feel free to edit that\n",
        "    plt.plot(y_test[-200:], c='b')\n",
        "    plt.plot(y_pred[-200:], c='r')\n",
        "    plt.xlabel(\"Days\")\n",
        "    plt.ylabel(\"Price\")\n",
        "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS1wGXe-qos4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "c822e7d1-eb01-4bfa-cf56-2317968277d1"
      },
      "source": [
        "plot_graph(model, data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQj9D-XSqyZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_accuracy(model, data):\n",
        "    y_test = data[\"y_test\"]\n",
        "    X_test = data[\"X_test\"]\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
        "    y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
        "    y_pred = list(map(lambda current, future: int(float(future) > float(current)), y_test[:-LOOKUP_STEP], y_pred[LOOKUP_STEP:]))\n",
        "    y_test = list(map(lambda current, future: int(float(future) > float(current)), y_test[:-LOOKUP_STEP], y_test[LOOKUP_STEP:]))\n",
        "    return accuracy_score(y_test, y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrHk2_Ifq2AC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b40d3038-5600-4a1d-a148-cc4074ef5378"
      },
      "source": [
        "print(str(LOOKUP_STEP) + \":\", \"Accuracy Score:\", get_accuracy(model, data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50: Accuracy Score: 0.9144942648592284\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}